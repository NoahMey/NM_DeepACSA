{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.backend import clear_session\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.applications import VGG16 \n",
    "from keras.layers import Input, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "\n",
    "#unet collection\n",
    "from keras_unet_collection import models\n",
    "#import tensorflow as tf\n",
    "from datetime import datetime \n",
    "from PIL import Image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net 3+ with Keras unet collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [64, 64, 64, 64]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 320\n",
      "Epoch 1/2\n",
      "196/230 [========================>.....] - ETA: 8:06 - loss: 0.2227 - accuracy: 0.9006 - IoU: 0.9290"
     ]
    }
   ],
   "source": [
    "image_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_images_RF/insert_images/'\n",
    "mask_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'\n",
    "\n",
    "SIZE = 256\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "#define custom function\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n",
    "\n",
    "#callback\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('BN.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger('BN.csv', separator=',', append=False)\n",
    "]\n",
    "\n",
    "images = os.listdir(image_directory)\n",
    "for i, image_name in enumerate(images):    #Remember enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        #print(image_directory+image_name)\n",
    "        image = cv2.imread(image_directory+image_name, 1)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        image_dataset.append(np.array(image))\n",
    "\n",
    "\n",
    "masks = os.listdir(mask_directory)\n",
    "for i, image_name in enumerate(masks):\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        image = cv2.imread(mask_directory+image_name, 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        mask_dataset.append(np.array(image))\n",
    "\n",
    "\n",
    "#Normalize images\n",
    "image_dataset = np.array(image_dataset)/255.\n",
    "#D not normalize masks, just rescale to 0 to 1.\n",
    "mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255.\n",
    "\n",
    "#split dataset into training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.10, random_state = 0)\n",
    "\n",
    "num_labels = 1  #Binary\n",
    "batch_size = 2\n",
    "epochs = 2\n",
    "\n",
    "model = models.unet_3plus_2d((256, 256, 3), n_labels=num_labels, filter_num_down=[64, 128, 256, 512, 1024], \n",
    "                             filter_num_skip='auto', filter_num_aggregate='auto', \n",
    "                             stack_num_down=2, stack_num_up=2, activation='ReLU', output_activation='Sigmoid',\n",
    "                             batch_norm=True, pool=True, unpool=False, deep_supervision=False, name='unet3plus')\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "              metrics=['accuracy', IoU])\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "start2 = datetime.now() \n",
    "\n",
    "Unet_plus_history = model.fit(X_train, y_train, \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(X_test, y_test), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "#print(\"Those are the metrics\", model.evaluate(X_test, y_test))\n",
    "stop2 = datetime.now()\n",
    "#Execution time of the model \n",
    "execution_time_Unet_plus = stop2-start2\n",
    "print(\"UNet plus execution time is: \", execution_time_Unet_plus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net3+ with Keras unet collection and k-fold-cross-validation (k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [64, 64, 64, 64]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 320\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/60\n",
      "205/205 [==============================] - 1940s 9s/step - loss: 0.1418 - accuracy: 0.9493 - IoU: 0.9558 - val_loss: 0.1931 - val_accuracy: 0.9593 - val_IoU: 0.9783\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19305, saving model to B2-Kfoldno1-unet3plus.h5\n",
      "Epoch 2/60\n",
      "205/205 [==============================] - 1886s 9s/step - loss: 0.0633 - accuracy: 0.9718 - IoU: 0.9782 - val_loss: 0.3734 - val_accuracy: 0.9467 - val_IoU: 0.9715\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19305\n",
      "Epoch 3/60\n",
      "205/205 [==============================] - 1889s 9s/step - loss: 0.0594 - accuracy: 0.9730 - IoU: 0.9803 - val_loss: 0.1181 - val_accuracy: 0.9649 - val_IoU: 0.9745\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.19305 to 0.11805, saving model to B2-Kfoldno1-unet3plus.h5\n",
      "Epoch 4/60\n",
      "205/205 [==============================] - 1884s 9s/step - loss: 0.0490 - accuracy: 0.9765 - IoU: 0.9828 - val_loss: 0.5809 - val_accuracy: 0.9132 - val_IoU: 0.9526\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.11805\n",
      "Epoch 5/60\n",
      "205/205 [==============================] - 1889s 9s/step - loss: 0.0469 - accuracy: 0.9772 - IoU: 0.9837 - val_loss: 6.8316 - val_accuracy: 0.7865 - val_IoU: 0.8902\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11805\n",
      "Epoch 6/60\n",
      "205/205 [==============================] - 1895s 9s/step - loss: 0.0444 - accuracy: 0.9786 - IoU: 0.9848 - val_loss: 0.0837 - val_accuracy: 0.9689 - val_IoU: 0.9790\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11805 to 0.08371, saving model to B2-Kfoldno1-unet3plus.h5\n",
      "Epoch 7/60\n",
      "205/205 [==============================] - 1890s 9s/step - loss: 0.0383 - accuracy: 0.9813 - IoU: 0.9867 - val_loss: 0.2187 - val_accuracy: 0.9248 - val_IoU: 0.9662\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08371\n",
      "Epoch 8/60\n",
      "205/205 [==============================] - 1888s 9s/step - loss: 0.0314 - accuracy: 0.9841 - IoU: 0.9892 - val_loss: 0.0461 - val_accuracy: 0.9775 - val_IoU: 0.9849\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.08371 to 0.04610, saving model to B2-Kfoldno1-unet3plus.h5\n",
      "Epoch 9/60\n",
      "205/205 [==============================] - 1889s 9s/step - loss: 0.0266 - accuracy: 0.9858 - IoU: 0.9908 - val_loss: 0.0966 - val_accuracy: 0.9587 - val_IoU: 0.9786\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04610\n",
      "Epoch 10/60\n",
      "205/205 [==============================] - 1893s 9s/step - loss: 0.0215 - accuracy: 0.9879 - IoU: 0.9925 - val_loss: 0.0426 - val_accuracy: 0.9806 - val_IoU: 0.9884\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04610 to 0.04257, saving model to B2-Kfoldno1-unet3plus.h5\n",
      "Epoch 11/60\n",
      "205/205 [==============================] - 1886s 9s/step - loss: 0.0178 - accuracy: 0.9892 - IoU: 0.9938 - val_loss: 0.0346 - val_accuracy: 0.9835 - val_IoU: 0.9889\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.04257 to 0.03460, saving model to B2-Kfoldno1-unet3plus.h5\n",
      "Epoch 12/60\n",
      "205/205 [==============================] - 1887s 9s/step - loss: 0.0153 - accuracy: 0.9901 - IoU: 0.9945 - val_loss: 0.0629 - val_accuracy: 0.9713 - val_IoU: 0.9759\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.03460\n",
      "Epoch 13/60\n",
      "205/205 [==============================] - 1888s 9s/step - loss: 0.0207 - accuracy: 0.9883 - IoU: 0.9928 - val_loss: 0.1870 - val_accuracy: 0.9419 - val_IoU: 0.9642\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.03460\n",
      "Epoch 14/60\n",
      "205/205 [==============================] - 1889s 9s/step - loss: 0.0191 - accuracy: 0.9889 - IoU: 0.9935 - val_loss: 0.1262 - val_accuracy: 0.9553 - val_IoU: 0.9775\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.03460\n",
      "Epoch 15/60\n",
      "205/205 [==============================] - 1894s 9s/step - loss: 0.0158 - accuracy: 0.9899 - IoU: 0.9943 - val_loss: 0.0818 - val_accuracy: 0.9710 - val_IoU: 0.9845\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.03460\n",
      "Epoch 16/60\n",
      "205/205 [==============================] - 1903s 9s/step - loss: 0.0125 - accuracy: 0.9911 - IoU: 0.9954 - val_loss: 0.0238 - val_accuracy: 0.9868 - val_IoU: 0.9923\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.03460 to 0.02382, saving model to B2-Kfoldno1-unet3plus.h5\n",
      "Epoch 17/60\n",
      "205/205 [==============================] - 1886s 9s/step - loss: 0.0118 - accuracy: 0.9915 - IoU: 0.9956 - val_loss: 0.0298 - val_accuracy: 0.9857 - val_IoU: 0.9926\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02382\n",
      "Epoch 18/60\n",
      "205/205 [==============================] - 1890s 9s/step - loss: 0.0137 - accuracy: 0.9907 - IoU: 0.9950 - val_loss: 0.0675 - val_accuracy: 0.9798 - val_IoU: 0.9790\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02382\n",
      "Epoch 19/60\n",
      "205/205 [==============================] - 1887s 9s/step - loss: 0.0132 - accuracy: 0.9910 - IoU: 0.9954 - val_loss: 0.0625 - val_accuracy: 0.9791 - val_IoU: 0.9891\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02382\n",
      "Epoch 20/60\n",
      "205/205 [==============================] - 1889s 9s/step - loss: 0.0107 - accuracy: 0.9918 - IoU: 0.9960 - val_loss: 0.0375 - val_accuracy: 0.9847 - val_IoU: 0.9925\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02382\n",
      "Epoch 21/60\n",
      "205/205 [==============================] - 1889s 9s/step - loss: 0.0097 - accuracy: 0.9922 - IoU: 0.9964 - val_loss: 0.0173 - val_accuracy: 0.9896 - val_IoU: 0.9949\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.02382 to 0.01733, saving model to B2-Kfoldno1-unet3plus.h5\n",
      "Epoch 22/60\n",
      "205/205 [==============================] - 1889s 9s/step - loss: 0.0096 - accuracy: 0.9922 - IoU: 0.9965 - val_loss: 0.0175 - val_accuracy: 0.9896 - val_IoU: 0.9948\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01733\n",
      "Epoch 23/60\n",
      "205/205 [==============================] - 1888s 9s/step - loss: 0.0123 - accuracy: 0.9912 - IoU: 0.9956 - val_loss: 42.2453 - val_accuracy: 0.7513 - val_IoU: 0.8578\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01733\n",
      "Epoch 24/60\n",
      "205/205 [==============================] - 1889s 9s/step - loss: 0.0193 - accuracy: 0.9892 - IoU: 0.9936 - val_loss: 0.0355 - val_accuracy: 0.9838 - val_IoU: 0.9915\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01733\n",
      "Epoch 25/60\n",
      "205/205 [==============================] - 1887s 9s/step - loss: 0.0116 - accuracy: 0.9913 - IoU: 0.9956 - val_loss: 0.0479 - val_accuracy: 0.9841 - val_IoU: 0.9921\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01733\n",
      "Epoch 26/60\n",
      "205/205 [==============================] - 1890s 9s/step - loss: 0.0100 - accuracy: 0.9920 - IoU: 0.9963 - val_loss: 0.0151 - val_accuracy: 0.9906 - val_IoU: 0.9957\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01733 to 0.01513, saving model to B2-Kfoldno1-unet3plus.h5\n",
      "Epoch 27/60\n",
      "205/205 [==============================] - 1884s 9s/step - loss: 0.0094 - accuracy: 0.9923 - IoU: 0.9965 - val_loss: 0.0121 - val_accuracy: 0.9916 - val_IoU: 0.9962\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01513 to 0.01206, saving model to B2-Kfoldno1-unet3plus.h5\n",
      "Epoch 28/60\n",
      "205/205 [==============================] - 1890s 9s/step - loss: 0.0085 - accuracy: 0.9926 - IoU: 0.9968 - val_loss: 0.0126 - val_accuracy: 0.9914 - val_IoU: 0.9961\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01206\n",
      "Epoch 29/60\n",
      "205/205 [==============================] - 1940s 9s/step - loss: 0.0081 - accuracy: 0.9928 - IoU: 0.9970 - val_loss: 0.0125 - val_accuracy: 0.9913 - val_IoU: 0.9961\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01206\n",
      "Epoch 30/60\n",
      "205/205 [==============================] - 1932s 9s/step - loss: 0.0087 - accuracy: 0.9926 - IoU: 0.9968 - val_loss: 0.0162 - val_accuracy: 0.9904 - val_IoU: 0.9956\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01206\n",
      "Epoch 31/60\n",
      "205/205 [==============================] - 1894s 9s/step - loss: 0.0082 - accuracy: 0.9927 - IoU: 0.9970 - val_loss: 0.0129 - val_accuracy: 0.9914 - val_IoU: 0.9962\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01206\n",
      "Epoch 32/60\n",
      "205/205 [==============================] - 1897s 9s/step - loss: 0.0080 - accuracy: 0.9927 - IoU: 0.9970 - val_loss: 0.0123 - val_accuracy: 0.9916 - val_IoU: 0.9964\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01206\n",
      "Epoch 33/60\n",
      "205/205 [==============================] - 1890s 9s/step - loss: 0.0092 - accuracy: 0.9924 - IoU: 0.9966 - val_loss: 0.0642 - val_accuracy: 0.9742 - val_IoU: 0.9845\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01206\n",
      "Epoch 34/60\n",
      "205/205 [==============================] - 1889s 9s/step - loss: 0.0150 - accuracy: 0.9904 - IoU: 0.9948 - val_loss: 0.0236 - val_accuracy: 0.9881 - val_IoU: 0.9937\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01206\n",
      "Epoch 35/60\n",
      "205/205 [==============================] - 1888s 9s/step - loss: 0.0119 - accuracy: 0.9915 - IoU: 0.9957 - val_loss: 0.1047 - val_accuracy: 0.9765 - val_IoU: 0.9877\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01206\n",
      "Epoch 00035: early stopping\n",
      "4/4 [==============================] - 91s 21s/step - loss: 0.1047 - accuracy: 0.9765 - IoU: 0.9877\n",
      "4/4 [==============================] - 90s 21s/step - loss: 0.1047 - accuracy: 0.9765 - IoU: 0.9877\n",
      "4/4 [==============================] - 90s 21s/step - loss: 0.1047 - accuracy: 0.9765 - IoU: 0.9877\n",
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [64, 64, 64, 64]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 320\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/60\n",
      "205/205 [==============================] - 1896s 9s/step - loss: 0.1918 - accuracy: 0.9330 - IoU: 0.9424 - val_loss: 0.5393 - val_accuracy: 0.9142 - val_IoU: 0.9575\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53926, saving model to B2-Kfoldno2-unet3plus.h5\n",
      "Epoch 2/60\n",
      "205/205 [==============================] - 1897s 9s/step - loss: 0.0600 - accuracy: 0.9721 - IoU: 0.9789 - val_loss: 0.1470 - val_accuracy: 0.9590 - val_IoU: 0.9772\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.53926 to 0.14696, saving model to B2-Kfoldno2-unet3plus.h5\n",
      "Epoch 3/60\n",
      "205/205 [==============================] - 1909s 9s/step - loss: 0.0531 - accuracy: 0.9752 - IoU: 0.9811 - val_loss: 0.3450 - val_accuracy: 0.9091 - val_IoU: 0.9457\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.14696\n",
      "Epoch 4/60\n",
      "205/205 [==============================] - 1914s 9s/step - loss: 0.0485 - accuracy: 0.9771 - IoU: 0.9826 - val_loss: 0.0550 - val_accuracy: 0.9754 - val_IoU: 0.9823\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.14696 to 0.05496, saving model to B2-Kfoldno2-unet3plus.h5\n",
      "Epoch 5/60\n",
      "205/205 [==============================] - 1887s 9s/step - loss: 0.0421 - accuracy: 0.9796 - IoU: 0.9848 - val_loss: 0.0653 - val_accuracy: 0.9741 - val_IoU: 0.9809\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05496\n",
      "Epoch 6/60\n",
      "205/205 [==============================] - 1890s 9s/step - loss: 0.0396 - accuracy: 0.9807 - IoU: 0.9858 - val_loss: 0.0461 - val_accuracy: 0.9792 - val_IoU: 0.9858\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05496 to 0.04612, saving model to B2-Kfoldno2-unet3plus.h5\n",
      "Epoch 7/60\n",
      "205/205 [==============================] - 1908s 9s/step - loss: 0.0352 - accuracy: 0.9824 - IoU: 0.9873 - val_loss: 0.0695 - val_accuracy: 0.9735 - val_IoU: 0.9836\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04612\n",
      "Epoch 8/60\n",
      "205/205 [==============================] - 1899s 9s/step - loss: 0.0335 - accuracy: 0.9833 - IoU: 0.9879 - val_loss: 0.0320 - val_accuracy: 0.9832 - val_IoU: 0.9884\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04612 to 0.03202, saving model to B2-Kfoldno2-unet3plus.h5\n",
      "Epoch 9/60\n",
      "205/205 [==============================] - 1895s 9s/step - loss: 0.0286 - accuracy: 0.9852 - IoU: 0.9898 - val_loss: 0.0605 - val_accuracy: 0.9733 - val_IoU: 0.9800\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03202\n",
      "Epoch 10/60\n",
      "205/205 [==============================] - 1896s 9s/step - loss: 0.0254 - accuracy: 0.9864 - IoU: 0.9909 - val_loss: 0.0309 - val_accuracy: 0.9841 - val_IoU: 0.9908\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03202 to 0.03095, saving model to B2-Kfoldno2-unet3plus.h5\n",
      "Epoch 11/60\n",
      "205/205 [==============================] - 1923s 9s/step - loss: 0.0237 - accuracy: 0.9871 - IoU: 0.9914 - val_loss: 0.0254 - val_accuracy: 0.9871 - val_IoU: 0.9918\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03095 to 0.02545, saving model to B2-Kfoldno2-unet3plus.h5\n",
      "Epoch 12/60\n",
      "205/205 [==============================] - 1900s 9s/step - loss: 0.0195 - accuracy: 0.9888 - IoU: 0.9931 - val_loss: 0.0306 - val_accuracy: 0.9853 - val_IoU: 0.9917\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02545\n",
      "Epoch 13/60\n",
      "205/205 [==============================] - 1911s 9s/step - loss: 0.0160 - accuracy: 0.9901 - IoU: 0.9943 - val_loss: 0.0300 - val_accuracy: 0.9843 - val_IoU: 0.9903\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02545\n",
      "Epoch 14/60\n",
      "205/205 [==============================] - 1907s 9s/step - loss: 0.0177 - accuracy: 0.9895 - IoU: 0.9937 - val_loss: 2.0023 - val_accuracy: 0.8641 - val_IoU: 0.9281\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02545\n",
      "Epoch 15/60\n",
      "205/205 [==============================] - 1907s 9s/step - loss: 0.0225 - accuracy: 0.9877 - IoU: 0.9922 - val_loss: 0.0273 - val_accuracy: 0.9862 - val_IoU: 0.9919\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02545\n",
      "Epoch 16/60\n",
      "205/205 [==============================] - 1899s 9s/step - loss: 0.0172 - accuracy: 0.9896 - IoU: 0.9938 - val_loss: 0.0130 - val_accuracy: 0.9909 - val_IoU: 0.9953\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02545 to 0.01304, saving model to B2-Kfoldno2-unet3plus.h5\n",
      "Epoch 17/60\n",
      "205/205 [==============================] - 1911s 9s/step - loss: 0.0125 - accuracy: 0.9913 - IoU: 0.9955 - val_loss: 0.0129 - val_accuracy: 0.9909 - val_IoU: 0.9955\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01304 to 0.01288, saving model to B2-Kfoldno2-unet3plus.h5\n",
      "Epoch 18/60\n",
      "205/205 [==============================] - 1910s 9s/step - loss: 0.0113 - accuracy: 0.9918 - IoU: 0.9959 - val_loss: 0.0117 - val_accuracy: 0.9914 - val_IoU: 0.9959\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01288 to 0.01167, saving model to B2-Kfoldno2-unet3plus.h5\n",
      "Epoch 19/60\n",
      "205/205 [==============================] - 1907s 9s/step - loss: 0.0103 - accuracy: 0.9921 - IoU: 0.9962 - val_loss: 0.0150 - val_accuracy: 0.9906 - val_IoU: 0.9956\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01167\n",
      "Epoch 20/60\n",
      "205/205 [==============================] - 1910s 9s/step - loss: 0.0165 - accuracy: 0.9900 - IoU: 0.9944 - val_loss: 0.0231 - val_accuracy: 0.9885 - val_IoU: 0.9940\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01167\n",
      "Epoch 21/60\n",
      "205/205 [==============================] - 1909s 9s/step - loss: 0.0158 - accuracy: 0.9903 - IoU: 0.9944 - val_loss: 0.0152 - val_accuracy: 0.9903 - val_IoU: 0.9951\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01167\n",
      "Epoch 22/60\n",
      "205/205 [==============================] - 1903s 9s/step - loss: 0.0110 - accuracy: 0.9918 - IoU: 0.9959 - val_loss: 0.0170 - val_accuracy: 0.9895 - val_IoU: 0.9948\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01167\n",
      "Epoch 23/60\n",
      "205/205 [==============================] - 1905s 9s/step - loss: 0.0105 - accuracy: 0.9920 - IoU: 0.9961 - val_loss: 0.0131 - val_accuracy: 0.9912 - val_IoU: 0.9960\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01167\n",
      "Epoch 24/60\n",
      "205/205 [==============================] - 1907s 9s/step - loss: 0.0094 - accuracy: 0.9923 - IoU: 0.9965 - val_loss: 0.0139 - val_accuracy: 0.9909 - val_IoU: 0.9959\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01167\n",
      "Epoch 25/60\n",
      "205/205 [==============================] - 1904s 9s/step - loss: 0.0097 - accuracy: 0.9923 - IoU: 0.9964 - val_loss: 0.0108 - val_accuracy: 0.9918 - val_IoU: 0.9966\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01167 to 0.01085, saving model to B2-Kfoldno2-unet3plus.h5\n",
      "Epoch 26/60\n",
      "205/205 [==============================] - 1908s 9s/step - loss: 0.0087 - accuracy: 0.9926 - IoU: 0.9968 - val_loss: 0.0149 - val_accuracy: 0.9913 - val_IoU: 0.9964\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01085\n",
      "Epoch 27/60\n",
      "205/205 [==============================] - 1911s 9s/step - loss: 0.0088 - accuracy: 0.9926 - IoU: 0.9968 - val_loss: 0.0157 - val_accuracy: 0.9911 - val_IoU: 0.9963\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01085\n",
      "Epoch 28/60\n",
      "205/205 [==============================] - 1940s 9s/step - loss: 0.0086 - accuracy: 0.9926 - IoU: 0.9968 - val_loss: 0.0133 - val_accuracy: 0.9916 - val_IoU: 0.9966\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01085\n",
      "Epoch 29/60\n",
      "205/205 [==============================] - 1913s 9s/step - loss: 0.0103 - accuracy: 0.9921 - IoU: 0.9964 - val_loss: 0.6540 - val_accuracy: 0.9432 - val_IoU: 0.9689\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01085\n",
      "Epoch 30/60\n",
      "205/205 [==============================] - 1913s 9s/step - loss: 0.0387 - accuracy: 0.9834 - IoU: 0.9886 - val_loss: 0.0219 - val_accuracy: 0.9875 - val_IoU: 0.9924\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01085\n",
      "Epoch 31/60\n",
      "205/205 [==============================] - 1910s 9s/step - loss: 0.0138 - accuracy: 0.9909 - IoU: 0.9950 - val_loss: 0.0311 - val_accuracy: 0.9842 - val_IoU: 0.9918\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01085\n",
      "Epoch 32/60\n",
      "205/205 [==============================] - 1911s 9s/step - loss: 0.0100 - accuracy: 0.9921 - IoU: 0.9963 - val_loss: 0.0113 - val_accuracy: 0.9917 - val_IoU: 0.9963\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01085\n",
      "Epoch 33/60\n",
      "205/205 [==============================] - 1916s 9s/step - loss: 0.0089 - accuracy: 0.9925 - IoU: 0.9967 - val_loss: 0.0184 - val_accuracy: 0.9902 - val_IoU: 0.9957\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01085\n",
      "Epoch 00033: early stopping\n",
      "4/4 [==============================] - 95s 22s/step - loss: 0.0184 - accuracy: 0.9902 - IoU: 0.9957\n",
      "4/4 [==============================] - 95s 22s/step - loss: 0.0184 - accuracy: 0.9902 - IoU: 0.9957\n",
      "4/4 [==============================] - 95s 22s/step - loss: 0.0184 - accuracy: 0.9902 - IoU: 0.9957\n",
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [64, 64, 64, 64]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 320\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/60\n",
      "205/205 [==============================] - 1928s 9s/step - loss: 0.1867 - accuracy: 0.9279 - IoU: 0.9420 - val_loss: 2.1533 - val_accuracy: 0.8806 - val_IoU: 0.9400\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.15327, saving model to B2-Kfoldno3-unet3plus.h5\n",
      "Epoch 2/60\n",
      "205/205 [==============================] - 1941s 9s/step - loss: 0.0540 - accuracy: 0.9760 - IoU: 0.9814 - val_loss: 0.3201 - val_accuracy: 0.9363 - val_IoU: 0.9663\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.15327 to 0.32013, saving model to B2-Kfoldno3-unet3plus.h5\n",
      "Epoch 3/60\n",
      "205/205 [==============================] - 2115s 10s/step - loss: 0.0462 - accuracy: 0.9786 - IoU: 0.9839 - val_loss: 0.3884 - val_accuracy: 0.9040 - val_IoU: 0.9458\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.32013\n",
      "Epoch 4/60\n",
      "205/205 [==============================] - 2096s 10s/step - loss: 0.0432 - accuracy: 0.9793 - IoU: 0.9850 - val_loss: 0.1750 - val_accuracy: 0.9390 - val_IoU: 0.9643\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.32013 to 0.17504, saving model to B2-Kfoldno3-unet3plus.h5\n",
      "Epoch 5/60\n",
      "205/205 [==============================] - 2103s 10s/step - loss: 0.0399 - accuracy: 0.9807 - IoU: 0.9857 - val_loss: 0.0720 - val_accuracy: 0.9666 - val_IoU: 0.9755\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.17504 to 0.07197, saving model to B2-Kfoldno3-unet3plus.h5\n",
      "Epoch 6/60\n",
      "205/205 [==============================] - 2066s 10s/step - loss: 0.0375 - accuracy: 0.9815 - IoU: 0.9867 - val_loss: 0.1071 - val_accuracy: 0.9558 - val_IoU: 0.9686\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.07197\n",
      "Epoch 7/60\n",
      "205/205 [==============================] - 2036s 10s/step - loss: 0.0322 - accuracy: 0.9839 - IoU: 0.9885 - val_loss: 0.0487 - val_accuracy: 0.9774 - val_IoU: 0.9832\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.07197 to 0.04871, saving model to B2-Kfoldno3-unet3plus.h5\n",
      "Epoch 8/60\n",
      "205/205 [==============================] - 2056s 10s/step - loss: 0.0233 - accuracy: 0.9875 - IoU: 0.9915 - val_loss: 0.0442 - val_accuracy: 0.9796 - val_IoU: 0.9856\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04871 to 0.04424, saving model to B2-Kfoldno3-unet3plus.h5\n",
      "Epoch 9/60\n",
      "205/205 [==============================] - 2061s 10s/step - loss: 0.0190 - accuracy: 0.9889 - IoU: 0.9931 - val_loss: 0.1079 - val_accuracy: 0.9622 - val_IoU: 0.9763\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04424\n",
      "Epoch 10/60\n",
      "205/205 [==============================] - 2046s 10s/step - loss: 0.0170 - accuracy: 0.9897 - IoU: 0.9939 - val_loss: 0.0880 - val_accuracy: 0.9708 - val_IoU: 0.9848\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.04424\n",
      "Epoch 11/60\n",
      "205/205 [==============================] - 2063s 10s/step - loss: 0.0152 - accuracy: 0.9904 - IoU: 0.9948 - val_loss: 0.0442 - val_accuracy: 0.9803 - val_IoU: 0.9875\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.04424 to 0.04421, saving model to B2-Kfoldno3-unet3plus.h5\n",
      "Epoch 12/60\n",
      "205/205 [==============================] - 2047s 10s/step - loss: 0.0128 - accuracy: 0.9913 - IoU: 0.9955 - val_loss: 0.0769 - val_accuracy: 0.9698 - val_IoU: 0.9820\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.04421\n",
      "Epoch 13/60\n",
      "205/205 [==============================] - 2047s 10s/step - loss: 0.0121 - accuracy: 0.9914 - IoU: 0.9958 - val_loss: 0.0418 - val_accuracy: 0.9825 - val_IoU: 0.9903\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.04421 to 0.04181, saving model to B2-Kfoldno3-unet3plus.h5\n",
      "Epoch 14/60\n",
      "205/205 [==============================] - 2036s 10s/step - loss: 0.0119 - accuracy: 0.9915 - IoU: 0.9959 - val_loss: 0.2068 - val_accuracy: 0.9507 - val_IoU: 0.9746\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04181\n",
      "Epoch 15/60\n",
      "205/205 [==============================] - 2058s 10s/step - loss: 0.0191 - accuracy: 0.9892 - IoU: 0.9938 - val_loss: 0.0526 - val_accuracy: 0.9777 - val_IoU: 0.9863\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04181\n",
      "Epoch 16/60\n",
      "205/205 [==============================] - 2039s 10s/step - loss: 0.0117 - accuracy: 0.9916 - IoU: 0.9959 - val_loss: 0.0767 - val_accuracy: 0.9758 - val_IoU: 0.9863\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04181\n",
      "Epoch 17/60\n",
      "205/205 [==============================] - 2030s 10s/step - loss: 0.0118 - accuracy: 0.9915 - IoU: 0.9957 - val_loss: 0.0777 - val_accuracy: 0.9727 - val_IoU: 0.9845\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04181\n",
      "Epoch 18/60\n",
      "205/205 [==============================] - 2051s 10s/step - loss: 0.0118 - accuracy: 0.9916 - IoU: 0.9959 - val_loss: 0.0382 - val_accuracy: 0.9821 - val_IoU: 0.9892\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.04181 to 0.03818, saving model to B2-Kfoldno3-unet3plus.h5\n",
      "Epoch 19/60\n",
      "205/205 [==============================] - 2049s 10s/step - loss: 0.0106 - accuracy: 0.9920 - IoU: 0.9962 - val_loss: 0.0388 - val_accuracy: 0.9833 - val_IoU: 0.9907\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.03818\n",
      "Epoch 20/60\n",
      "205/205 [==============================] - 2031s 10s/step - loss: 0.0093 - accuracy: 0.9924 - IoU: 0.9966 - val_loss: 0.0315 - val_accuracy: 0.9868 - val_IoU: 0.9935\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.03818 to 0.03148, saving model to B2-Kfoldno3-unet3plus.h5\n",
      "Epoch 21/60\n",
      "205/205 [==============================] - 2019s 10s/step - loss: 0.0090 - accuracy: 0.9925 - IoU: 0.9967 - val_loss: 0.0388 - val_accuracy: 0.9850 - val_IoU: 0.9917\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.03148\n",
      "Epoch 22/60\n",
      "205/205 [==============================] - 2022s 10s/step - loss: 0.0106 - accuracy: 0.9919 - IoU: 0.9962 - val_loss: 0.0544 - val_accuracy: 0.9822 - val_IoU: 0.9909\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.03148\n",
      "Epoch 23/60\n",
      "205/205 [==============================] - 2023s 10s/step - loss: 0.0091 - accuracy: 0.9925 - IoU: 0.9967 - val_loss: 0.0315 - val_accuracy: 0.9875 - val_IoU: 0.9937\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.03148\n",
      "Epoch 24/60\n",
      "205/205 [==============================] - 2020s 10s/step - loss: 0.0087 - accuracy: 0.9926 - IoU: 0.9968 - val_loss: 0.0327 - val_accuracy: 0.9872 - val_IoU: 0.9939\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.03148\n",
      "Epoch 25/60\n",
      "205/205 [==============================] - 2018s 10s/step - loss: 0.0091 - accuracy: 0.9925 - IoU: 0.9967 - val_loss: 0.0486 - val_accuracy: 0.9852 - val_IoU: 0.9928\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.03148\n",
      "Epoch 26/60\n",
      "205/205 [==============================] - 2036s 10s/step - loss: 0.0085 - accuracy: 0.9927 - IoU: 0.9969 - val_loss: 0.0470 - val_accuracy: 0.9820 - val_IoU: 0.9907\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03148\n",
      "Epoch 27/60\n",
      "205/205 [==============================] - 2023s 10s/step - loss: 0.0085 - accuracy: 0.9927 - IoU: 0.9969 - val_loss: 0.8284 - val_accuracy: 0.8897 - val_IoU: 0.9398\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.03148\n",
      "Epoch 28/60\n",
      "205/205 [==============================] - 2017s 10s/step - loss: 0.0166 - accuracy: 0.9900 - IoU: 0.9943 - val_loss: 0.1020 - val_accuracy: 0.9739 - val_IoU: 0.9859\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.03148\n",
      "Epoch 00028: early stopping\n",
      "4/4 [==============================] - 116s 26s/step - loss: 0.1020 - accuracy: 0.9739 - IoU: 0.9859\n",
      "4/4 [==============================] - 119s 27s/step - loss: 0.1020 - accuracy: 0.9739 - IoU: 0.9859\n",
      "4/4 [==============================] - 119s 27s/step - loss: 0.1020 - accuracy: 0.9739 - IoU: 0.9859\n",
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [64, 64, 64, 64]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 320\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/60\n",
      "205/205 [==============================] - 2064s 10s/step - loss: 0.1536 - accuracy: 0.9443 - IoU: 0.9523 - val_loss: 1.2684 - val_accuracy: 0.8969 - val_IoU: 0.9477\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.26836, saving model to B2-Kfoldno4-unet3plus.h5\n",
      "Epoch 2/60\n",
      "205/205 [==============================] - 2091s 10s/step - loss: 0.0497 - accuracy: 0.9770 - IoU: 0.9825 - val_loss: 8.9240 - val_accuracy: 0.6166 - val_IoU: 0.8045\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.26836\n",
      "Epoch 3/60\n",
      "205/205 [==============================] - 2096s 10s/step - loss: 0.0439 - accuracy: 0.9791 - IoU: 0.9845 - val_loss: 0.2539 - val_accuracy: 0.9408 - val_IoU: 0.9660\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.26836 to 0.25388, saving model to B2-Kfoldno4-unet3plus.h5\n",
      "Epoch 4/60\n",
      "205/205 [==============================] - 2062s 10s/step - loss: 0.0380 - accuracy: 0.9816 - IoU: 0.9869 - val_loss: 1.2648 - val_accuracy: 0.8305 - val_IoU: 0.9101\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25388\n",
      "Epoch 5/60\n",
      "205/205 [==============================] - 2051s 10s/step - loss: 0.0348 - accuracy: 0.9826 - IoU: 0.9877 - val_loss: 0.0608 - val_accuracy: 0.9738 - val_IoU: 0.9835\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.25388 to 0.06077, saving model to B2-Kfoldno4-unet3plus.h5\n",
      "Epoch 6/60\n",
      "205/205 [==============================] - 2100s 10s/step - loss: 0.0257 - accuracy: 0.9861 - IoU: 0.9908 - val_loss: 0.1142 - val_accuracy: 0.9547 - val_IoU: 0.9675\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06077\n",
      "Epoch 7/60\n",
      "205/205 [==============================] - 2079s 10s/step - loss: 0.0230 - accuracy: 0.9874 - IoU: 0.9919 - val_loss: 0.5380 - val_accuracy: 0.8891 - val_IoU: 0.9323\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06077\n",
      "Epoch 8/60\n",
      "205/205 [==============================] - 2090s 10s/step - loss: 0.0201 - accuracy: 0.9884 - IoU: 0.9929 - val_loss: 0.0553 - val_accuracy: 0.9795 - val_IoU: 0.9884\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06077 to 0.05531, saving model to B2-Kfoldno4-unet3plus.h5\n",
      "Epoch 9/60\n",
      "205/205 [==============================] - 2116s 10s/step - loss: 0.0175 - accuracy: 0.9894 - IoU: 0.9937 - val_loss: 1.9368 - val_accuracy: 0.7881 - val_IoU: 0.8847\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05531\n",
      "Epoch 10/60\n",
      "205/205 [==============================] - 2091s 10s/step - loss: 0.0203 - accuracy: 0.9885 - IoU: 0.9931 - val_loss: 0.2071 - val_accuracy: 0.9521 - val_IoU: 0.9668\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05531\n",
      "Epoch 11/60\n",
      "205/205 [==============================] - 2089s 10s/step - loss: 0.0170 - accuracy: 0.9896 - IoU: 0.9940 - val_loss: 0.3454 - val_accuracy: 0.8787 - val_IoU: 0.9236\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.05531\n",
      "Epoch 12/60\n",
      "205/205 [==============================] - 2119s 10s/step - loss: 0.0189 - accuracy: 0.9891 - IoU: 0.9931 - val_loss: 0.0398 - val_accuracy: 0.9842 - val_IoU: 0.9909\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.05531 to 0.03982, saving model to B2-Kfoldno4-unet3plus.h5\n",
      "Epoch 13/60\n",
      "205/205 [==============================] - 2117s 10s/step - loss: 0.0132 - accuracy: 0.9911 - IoU: 0.9952 - val_loss: 0.0396 - val_accuracy: 0.9845 - val_IoU: 0.9910\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03982 to 0.03961, saving model to B2-Kfoldno4-unet3plus.h5\n",
      "Epoch 14/60\n",
      "205/205 [==============================] - 2128s 10s/step - loss: 0.0119 - accuracy: 0.9915 - IoU: 0.9956 - val_loss: 0.0397 - val_accuracy: 0.9851 - val_IoU: 0.9924\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.03961\n",
      "Epoch 15/60\n",
      "205/205 [==============================] - 2166s 11s/step - loss: 0.0112 - accuracy: 0.9918 - IoU: 0.9958 - val_loss: 0.0619 - val_accuracy: 0.9797 - val_IoU: 0.9894\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.03961\n",
      "Epoch 16/60\n",
      "205/205 [==============================] - 2163s 11s/step - loss: 0.0101 - accuracy: 0.9921 - IoU: 0.9963 - val_loss: 0.0581 - val_accuracy: 0.9818 - val_IoU: 0.9911\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.03961\n",
      "Epoch 17/60\n",
      "205/205 [==============================] - 2294s 11s/step - loss: 0.0097 - accuracy: 0.9922 - IoU: 0.9964 - val_loss: 0.0412 - val_accuracy: 0.9841 - val_IoU: 0.9921\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.03961\n",
      "Epoch 18/60\n",
      "205/205 [==============================] - 2213s 11s/step - loss: 0.0097 - accuracy: 0.9922 - IoU: 0.9964 - val_loss: 0.0285 - val_accuracy: 0.9869 - val_IoU: 0.9931\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.03961 to 0.02853, saving model to B2-Kfoldno4-unet3plus.h5\n",
      "Epoch 19/60\n",
      "205/205 [==============================] - 2145s 10s/step - loss: 0.0096 - accuracy: 0.9923 - IoU: 0.9965 - val_loss: 0.0786 - val_accuracy: 0.9770 - val_IoU: 0.9885\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02853\n",
      "Epoch 20/60\n",
      "205/205 [==============================] - 2102s 10s/step - loss: 0.0104 - accuracy: 0.9920 - IoU: 0.9962 - val_loss: 0.0721 - val_accuracy: 0.9812 - val_IoU: 0.9905\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02853\n",
      "Epoch 21/60\n",
      "205/205 [==============================] - 2101s 10s/step - loss: 0.0122 - accuracy: 0.9914 - IoU: 0.9956 - val_loss: 0.0963 - val_accuracy: 0.9742 - val_IoU: 0.9859\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.02853\n",
      "Epoch 22/60\n",
      "205/205 [==============================] - 2106s 10s/step - loss: 0.0142 - accuracy: 0.9906 - IoU: 0.9951 - val_loss: 0.4362 - val_accuracy: 0.9022 - val_IoU: 0.9409\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.02853\n",
      "Epoch 23/60\n",
      "205/205 [==============================] - 2102s 10s/step - loss: 0.0175 - accuracy: 0.9895 - IoU: 0.9941 - val_loss: 0.3253 - val_accuracy: 0.9327 - val_IoU: 0.9680\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.02853\n",
      "Epoch 24/60\n",
      "205/205 [==============================] - 2098s 10s/step - loss: 0.0120 - accuracy: 0.9916 - IoU: 0.9957 - val_loss: 0.0327 - val_accuracy: 0.9850 - val_IoU: 0.9913\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.02853\n",
      "Epoch 25/60\n",
      "205/205 [==============================] - 2107s 10s/step - loss: 0.0108 - accuracy: 0.9919 - IoU: 0.9960 - val_loss: 0.0323 - val_accuracy: 0.9860 - val_IoU: 0.9928\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.02853\n",
      "Epoch 26/60\n",
      "205/205 [==============================] - 2096s 10s/step - loss: 0.0097 - accuracy: 0.9922 - IoU: 0.9965 - val_loss: 0.0319 - val_accuracy: 0.9874 - val_IoU: 0.9939\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.02853\n",
      "Epoch 00026: early stopping\n",
      "4/4 [==============================] - 223s 53s/step - loss: 0.0319 - accuracy: 0.9874 - IoU: 0.9939\n",
      "4/4 [==============================] - 233s 53s/step - loss: 0.0319 - accuracy: 0.9874 - IoU: 0.9939\n",
      "4/4 [==============================] - 234s 53s/step - loss: 0.0319 - accuracy: 0.9874 - IoU: 0.9939\n",
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [64, 64, 64, 64]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 320\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/60\n",
      "205/205 [==============================] - 2080s 10s/step - loss: 0.1756 - accuracy: 0.9291 - IoU: 0.9450 - val_loss: 0.2473 - val_accuracy: 0.9278 - val_IoU: 0.9540\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24731, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 2/60\n",
      "205/205 [==============================] - 2012s 10s/step - loss: 0.0502 - accuracy: 0.9768 - IoU: 0.9818 - val_loss: 0.2175 - val_accuracy: 0.9373 - val_IoU: 0.9613\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24731 to 0.21755, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 3/60\n",
      "205/205 [==============================] - 1999s 10s/step - loss: 0.0430 - accuracy: 0.9796 - IoU: 0.9847 - val_loss: 0.1498 - val_accuracy: 0.9367 - val_IoU: 0.9419\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21755 to 0.14980, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 4/60\n",
      "205/205 [==============================] - 2007s 10s/step - loss: 0.0402 - accuracy: 0.9809 - IoU: 0.9851 - val_loss: 0.3623 - val_accuracy: 0.8900 - val_IoU: 0.9150\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.14980\n",
      "Epoch 5/60\n",
      "205/205 [==============================] - 2104s 10s/step - loss: 0.0350 - accuracy: 0.9832 - IoU: 0.9875 - val_loss: 0.0606 - val_accuracy: 0.9752 - val_IoU: 0.9830\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.14980 to 0.06059, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 6/60\n",
      "205/205 [==============================] - 2111s 10s/step - loss: 0.0284 - accuracy: 0.9856 - IoU: 0.9897 - val_loss: 0.1362 - val_accuracy: 0.9520 - val_IoU: 0.9713\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06059\n",
      "Epoch 7/60\n",
      "205/205 [==============================] - 2054s 10s/step - loss: 0.0247 - accuracy: 0.9870 - IoU: 0.9912 - val_loss: 0.0818 - val_accuracy: 0.9715 - val_IoU: 0.9808\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06059\n",
      "Epoch 8/60\n",
      "205/205 [==============================] - 2020s 10s/step - loss: 0.0202 - accuracy: 0.9886 - IoU: 0.9929 - val_loss: 0.0452 - val_accuracy: 0.9803 - val_IoU: 0.9867\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06059 to 0.04516, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 9/60\n",
      "205/205 [==============================] - 2012s 10s/step - loss: 0.0192 - accuracy: 0.9890 - IoU: 0.9932 - val_loss: 0.1528 - val_accuracy: 0.9559 - val_IoU: 0.9715\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.04516\n",
      "Epoch 10/60\n",
      "205/205 [==============================] - 2018s 10s/step - loss: 0.0162 - accuracy: 0.9901 - IoU: 0.9941 - val_loss: 0.0282 - val_accuracy: 0.9857 - val_IoU: 0.9910\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04516 to 0.02823, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 11/60\n",
      "205/205 [==============================] - 2047s 10s/step - loss: 0.0149 - accuracy: 0.9905 - IoU: 0.9947 - val_loss: 0.0670 - val_accuracy: 0.9736 - val_IoU: 0.9826\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02823\n",
      "Epoch 12/60\n",
      "205/205 [==============================] - 2060s 10s/step - loss: 0.0153 - accuracy: 0.9905 - IoU: 0.9945 - val_loss: 0.6560 - val_accuracy: 0.8456 - val_IoU: 0.9158\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02823\n",
      "Epoch 13/60\n",
      "205/205 [==============================] - 2045s 10s/step - loss: 0.0169 - accuracy: 0.9898 - IoU: 0.9941 - val_loss: 0.0385 - val_accuracy: 0.9824 - val_IoU: 0.9892\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02823\n",
      "Epoch 14/60\n",
      "205/205 [==============================] - 2052s 10s/step - loss: 0.0140 - accuracy: 0.9908 - IoU: 0.9948 - val_loss: 0.0276 - val_accuracy: 0.9862 - val_IoU: 0.9923\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02823 to 0.02764, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 15/60\n",
      "205/205 [==============================] - 1990s 10s/step - loss: 0.0115 - accuracy: 0.9916 - IoU: 0.9957 - val_loss: 0.0253 - val_accuracy: 0.9876 - val_IoU: 0.9933\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02764 to 0.02527, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 16/60\n",
      "205/205 [==============================] - 2031s 10s/step - loss: 0.0110 - accuracy: 0.9918 - IoU: 0.9959 - val_loss: 0.0341 - val_accuracy: 0.9860 - val_IoU: 0.9927\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02527\n",
      "Epoch 17/60\n",
      "205/205 [==============================] - 2027s 10s/step - loss: 0.0102 - accuracy: 0.9920 - IoU: 0.9962 - val_loss: 0.0198 - val_accuracy: 0.9895 - val_IoU: 0.9946\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.02527 to 0.01981, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 18/60\n",
      "205/205 [==============================] - 1982s 10s/step - loss: 0.0104 - accuracy: 0.9920 - IoU: 0.9963 - val_loss: 0.1168 - val_accuracy: 0.9668 - val_IoU: 0.9802\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01981\n",
      "Epoch 19/60\n",
      "205/205 [==============================] - 2006s 10s/step - loss: 0.0122 - accuracy: 0.9914 - IoU: 0.9957 - val_loss: 0.0551 - val_accuracy: 0.9789 - val_IoU: 0.9875\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01981\n",
      "Epoch 20/60\n",
      "205/205 [==============================] - 2005s 10s/step - loss: 0.0123 - accuracy: 0.9912 - IoU: 0.9955 - val_loss: 0.0228 - val_accuracy: 0.9882 - val_IoU: 0.9936\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01981\n",
      "Epoch 21/60\n",
      "205/205 [==============================] - 2001s 10s/step - loss: 0.0097 - accuracy: 0.9923 - IoU: 0.9965 - val_loss: 0.0216 - val_accuracy: 0.9892 - val_IoU: 0.9946\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01981\n",
      "Epoch 22/60\n",
      "205/205 [==============================] - 2002s 10s/step - loss: 0.0087 - accuracy: 0.9926 - IoU: 0.9968 - val_loss: 0.0195 - val_accuracy: 0.9895 - val_IoU: 0.9946\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01981 to 0.01951, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 23/60\n",
      "205/205 [==============================] - 2013s 10s/step - loss: 0.0083 - accuracy: 0.9927 - IoU: 0.9969 - val_loss: 0.0193 - val_accuracy: 0.9898 - val_IoU: 0.9950\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01951 to 0.01933, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 24/60\n",
      "205/205 [==============================] - 2024s 10s/step - loss: 0.0082 - accuracy: 0.9927 - IoU: 0.9969 - val_loss: 0.0241 - val_accuracy: 0.9884 - val_IoU: 0.9943\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01933\n",
      "Epoch 25/60\n",
      "205/205 [==============================] - 2027s 10s/step - loss: 0.0079 - accuracy: 0.9929 - IoU: 0.9970 - val_loss: 0.0179 - val_accuracy: 0.9902 - val_IoU: 0.9954\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01933 to 0.01795, saving model to B2-Kfoldno5-unet3plus.h5\n",
      "Epoch 26/60\n",
      "205/205 [==============================] - 2025s 10s/step - loss: 0.0078 - accuracy: 0.9929 - IoU: 0.9971 - val_loss: 0.0201 - val_accuracy: 0.9901 - val_IoU: 0.9955\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01795\n",
      "Epoch 27/60\n",
      "205/205 [==============================] - 2028s 10s/step - loss: 0.0075 - accuracy: 0.9930 - IoU: 0.9972 - val_loss: 0.0247 - val_accuracy: 0.9893 - val_IoU: 0.9951\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01795\n",
      "Epoch 28/60\n",
      "205/205 [==============================] - 2049s 10s/step - loss: 0.0102 - accuracy: 0.9921 - IoU: 0.9964 - val_loss: 1.4200 - val_accuracy: 0.9055 - val_IoU: 0.9440\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01795\n",
      "Epoch 29/60\n",
      "205/205 [==============================] - 2094s 10s/step - loss: 0.0313 - accuracy: 0.9856 - IoU: 0.9900 - val_loss: 0.0629 - val_accuracy: 0.9779 - val_IoU: 0.9872\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01795\n",
      "Epoch 30/60\n",
      "205/205 [==============================] - 2079s 10s/step - loss: 0.0135 - accuracy: 0.9912 - IoU: 0.9951 - val_loss: 0.0251 - val_accuracy: 0.9878 - val_IoU: 0.9931\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01795\n",
      "Epoch 31/60\n",
      "205/205 [==============================] - 2091s 10s/step - loss: 0.0107 - accuracy: 0.9920 - IoU: 0.9961 - val_loss: 0.0239 - val_accuracy: 0.9882 - val_IoU: 0.9935\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01795\n",
      "Epoch 32/60\n",
      "205/205 [==============================] - 2114s 10s/step - loss: 0.0095 - accuracy: 0.9923 - IoU: 0.9965 - val_loss: 0.0226 - val_accuracy: 0.9894 - val_IoU: 0.9949\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01795\n",
      "Epoch 33/60\n",
      "205/205 [==============================] - 2038s 10s/step - loss: 0.0082 - accuracy: 0.9928 - IoU: 0.9969 - val_loss: 0.0188 - val_accuracy: 0.9900 - val_IoU: 0.9952\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01795\n",
      "Epoch 00033: early stopping\n",
      "4/4 [==============================] - 196s 51s/step - loss: 0.0188 - accuracy: 0.9900 - IoU: 0.9952\n",
      "4/4 [==============================] - 227s 52s/step - loss: 0.0188 - accuracy: 0.9900 - IoU: 0.9952\n",
      "4/4 [==============================] - 225s 51s/step - loss: 0.0188 - accuracy: 0.9900 - IoU: 0.9952\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.10472605377435684 - Accuracy: 0.9764919877052307 - IoU: 0.9877456426620483%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.018424026668071747 - Accuracy: 0.9902056455612183 - IoU: 0.9956629276275635%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.10203079879283905 - Accuracy: 0.9739194512367249 - IoU: 0.9858972430229187%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.031918853521347046 - Accuracy: 0.9873659014701843 - IoU: 0.9938597679138184%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.018807964399456978 - Accuracy: 0.9899884462356567 - IoU: 0.9952130317687988%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 0.983594286441803 (+- 0.006969440614374424)\n",
      "> Loss: 0.05518153943121433\n",
      "> IoU: 0.9916757225990296\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#define directory where images and masks are located\n",
    "image_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_images_VL/insert_images/'\n",
    "mask_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_VL/insert_masks/'\n",
    "\n",
    "#define the \n",
    "SIZE = 256\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "#define custom function\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n",
    "\n",
    "#enumerate and resize images/masks\n",
    "images = os.listdir(image_directory)\n",
    "for i, image_name in enumerate(images):    #enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        #print(image_directory+image_name)\n",
    "        image = cv2.imread(image_directory+image_name, 1)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        image_dataset.append(np.array(image))\n",
    "\n",
    "masks = os.listdir(mask_directory)\n",
    "for i, image_name in enumerate(masks):\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        image = cv2.imread(mask_directory+image_name, 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        mask_dataset.append(np.array(image))\n",
    "\n",
    "num_labels = 1  #Binary\n",
    "batch_size = 2\n",
    "epochs = 60\n",
    "num_folds = 5\n",
    "\n",
    "#Normalize images\n",
    "image_dataset = np.array(image_dataset)/255.\n",
    "#D not normalize masks, just rescale to 0 to 1.\n",
    "mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255.\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "# Define per-fold score containers \n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "IoU_per_fold = []\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "\n",
    "  callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(f'B1VL-Kfoldno{fold_no}-unet3plus.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger(f'B1VL-Kfoldno{fold_no}-unet3plus.csv', separator=',', append=False)]\n",
    "\n",
    "  # Define the model architecture\n",
    "  # unet_plus_2d require depth >= 2\n",
    "  model = models.unet_3plus_2d((256, 256, 3), n_labels=num_labels, filter_num_down=[64, 128, 256, 512, 1024], \n",
    "                             filter_num_skip='auto', filter_num_aggregate='auto', \n",
    "                             stack_num_down=2, stack_num_up=2, activation='ReLU', output_activation='Sigmoid',\n",
    "                             batch_norm=True, pool=True, unpool=False, deep_supervision=False, name='unet3plus')\n",
    "  # Compile the model\n",
    "  model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "              metrics=['accuracy', IoU])\n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  Unet_plus_history = model.fit(image_dataset[train], mask_dataset[train], \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(image_dataset[test], mask_dataset[test]), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "  \n",
    "  #append evaluation values for every fold to a list\n",
    "  acc_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[1])\n",
    "  loss_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[0])\n",
    "  IoU_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[2])\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no += 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - IoU: {IoU_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print(f'> IoU: {np.mean(IoU_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_apo = load_model(\"VGG16pre-Gastro-256.h5\", custom_objects={'IoU': IoU})\n",
    "model_apo.evaluate(X_valid, y_valid, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepACSA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "e822ee9ad92f536afc676ef91e9a5537e3a75846e0594120d7bb5c47379f58e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
