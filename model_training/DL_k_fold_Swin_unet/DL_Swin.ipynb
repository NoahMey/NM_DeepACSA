{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import random\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "#import glob\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use(\"ggplot\")\n",
    "#%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import cv2\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras_unet_collection import models #Keras unet collection\n",
    "#import tensorflow as tf\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Swin without k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 256, 2)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 68\u001b[0m\n\u001b[0;32m     60\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[0;32m     61\u001b[0m   EarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m     62\u001b[0m   ReduceLROnPlateau(factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m     63\u001b[0m   ModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39mA_modelSwinV1.h5\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_weights_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), \u001b[39m# Give the model a name (the .h5 part)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m   CSVLogger(\u001b[39m'\u001b[39m\u001b[39mA_modelSwinV1.csv\u001b[39m\u001b[39m'\u001b[39m, separator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)]\n\u001b[0;32m     66\u001b[0m \u001b[39m#define the model architecture\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m#this model requires depth >= 2\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39;49mswin_unet_2d((\u001b[39m256\u001b[39;49m, \u001b[39m256\u001b[39;49m, \u001b[39m3\u001b[39;49m), filter_num_begin\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, n_labels\u001b[39m=\u001b[39;49mnum_labels, depth\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, stack_num_down\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, stack_num_up\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \n\u001b[0;32m     69\u001b[0m                             patch_size\u001b[39m=\u001b[39;49m(\u001b[39m4\u001b[39;49m, \u001b[39m4\u001b[39;49m), num_heads\u001b[39m=\u001b[39;49m[\u001b[39m4\u001b[39;49m, \u001b[39m8\u001b[39;49m, \u001b[39m8\u001b[39;49m, \u001b[39m8\u001b[39;49m], window_size\u001b[39m=\u001b[39;49m[\u001b[39m4\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m], num_mlp\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, \n\u001b[0;32m     70\u001b[0m                             output_activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mSoftmax\u001b[39;49m\u001b[39m'\u001b[39;49m, shift_window\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mswin_unet\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m#Guess: Shift_window = False\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m#compile the model\u001b[39;00m\n\u001b[0;32m     73\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39mAdam(lr \u001b[39m=\u001b[39m \u001b[39m1e-3\u001b[39m), \n\u001b[0;32m     74\u001b[0m             metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, IoU])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_unet_collection\\_model_swin_unet_2d.py:230\u001b[0m, in \u001b[0;36mswin_unet_2d\u001b[1;34m(input_size, filter_num_begin, n_labels, depth, stack_num_down, stack_num_up, patch_size, num_heads, window_size, num_mlp, output_activation, shift_window, name)\u001b[0m\n\u001b[0;32m    227\u001b[0m IN \u001b[39m=\u001b[39m Input(input_size)\n\u001b[0;32m    229\u001b[0m \u001b[39m# base    \u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m X \u001b[39m=\u001b[39m swin_unet_2d_base(IN, filter_num_begin\u001b[39m=\u001b[39;49mfilter_num_begin, depth\u001b[39m=\u001b[39;49mdepth, stack_num_down\u001b[39m=\u001b[39;49mstack_num_down, stack_num_up\u001b[39m=\u001b[39;49mstack_num_up, \n\u001b[0;32m    231\u001b[0m                       patch_size\u001b[39m=\u001b[39;49mpatch_size, num_heads\u001b[39m=\u001b[39;49mnum_heads, window_size\u001b[39m=\u001b[39;49mwindow_size, num_mlp\u001b[39m=\u001b[39;49mnum_mlp, shift_window\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    233\u001b[0m \u001b[39m# output layer\u001b[39;00m\n\u001b[0;32m    234\u001b[0m OUT \u001b[39m=\u001b[39m CONV_output(X, n_labels, kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39moutput_activation, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_output\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_unet_collection\\_model_swin_unet_2d.py:168\u001b[0m, in \u001b[0;36mswin_unet_2d_base\u001b[1;34m(input_tensor, filter_num_begin, depth, stack_num_down, stack_num_up, patch_size, num_heads, window_size, num_mlp, shift_window, name)\u001b[0m\n\u001b[0;32m    165\u001b[0m     X \u001b[39m=\u001b[39m Dense(embed_dim, use_bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_concat_linear_proj_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, i))(X)\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Swin Transformer stacks\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     X \u001b[39m=\u001b[39m swin_transformer_stack(X, stack_num\u001b[39m=\u001b[39;49mstack_num_up, \n\u001b[0;32m    169\u001b[0m                        embed_dim\u001b[39m=\u001b[39;49membed_dim, num_patch\u001b[39m=\u001b[39;49m(num_patch_x, num_patch_y), \n\u001b[0;32m    170\u001b[0m                        num_heads\u001b[39m=\u001b[39;49mnum_heads[i], window_size\u001b[39m=\u001b[39;49mwindow_size[i], num_mlp\u001b[39m=\u001b[39;49mnum_mlp, \n\u001b[0;32m    171\u001b[0m                        shift_window\u001b[39m=\u001b[39;49mshift_window, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m_swin_up\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(name, i))\n\u001b[0;32m    173\u001b[0m \u001b[39m# The last expanding layer; it produces full-size feature maps based on the patch size\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39m# !!! <--- \"patch_size[0]\" is used; it assumes patch_size = (size, size)\u001b[39;00m\n\u001b[0;32m    175\u001b[0m X \u001b[39m=\u001b[39m patch_expanding(num_patch\u001b[39m=\u001b[39m(num_patch_x, num_patch_y),\n\u001b[0;32m    176\u001b[0m                     embed_dim\u001b[39m=\u001b[39membed_dim, upsample_rate\u001b[39m=\u001b[39mpatch_size[\u001b[39m0\u001b[39m], return_vector\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_unet_collection\\_model_swin_unet_2d.py:38\u001b[0m, in \u001b[0;36mswin_transformer_stack\u001b[1;34m(X, stack_num, embed_dim, num_patch, num_heads, window_size, num_mlp, shift_window, name)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m         shift_size_temp \u001b[39m=\u001b[39m shift_size\n\u001b[1;32m---> 38\u001b[0m     X \u001b[39m=\u001b[39m SwinTransformerBlock(dim\u001b[39m=\u001b[39;49membed_dim, num_patch\u001b[39m=\u001b[39;49mnum_patch, num_heads\u001b[39m=\u001b[39;49mnum_heads, \n\u001b[0;32m     39\u001b[0m                              window_size\u001b[39m=\u001b[39;49mwindow_size, shift_size\u001b[39m=\u001b[39;49mshift_size_temp, num_mlp\u001b[39m=\u001b[39;49mnum_mlp, qkv_bias\u001b[39m=\u001b[39;49mqkv_bias, qk_scale\u001b[39m=\u001b[39;49mqk_scale,\n\u001b[0;32m     40\u001b[0m                              mlp_drop\u001b[39m=\u001b[39;49mmlp_drop_rate, attn_drop\u001b[39m=\u001b[39;49mattn_drop_rate, proj_drop\u001b[39m=\u001b[39;49mproj_drop_rate, drop_path_prob\u001b[39m=\u001b[39;49mdrop_path_rate, \n\u001b[0;32m     41\u001b[0m                              name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(i))(X)\n\u001b[0;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:951\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    947\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    949\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 951\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m    952\u001b[0m                                             input_list)\n\u001b[0;32m    954\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m    955\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1090\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[39mif\u001b[39;00m keras_tensor\u001b[39m.\u001b[39mkeras_tensors_enabled():\n\u001b[0;32m   1087\u001b[0m   \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[0;32m   1088\u001b[0m       layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[0;32m   1089\u001b[0m     \u001b[39m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[1;32m-> 1090\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[0;32m   1091\u001b[0m         inputs, input_masks, args, kwargs)\n\u001b[0;32m   1093\u001b[0m     \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1095\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1096\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:822\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m   \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mmap_structure(keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature)\n\u001b[0;32m    821\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 822\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:863\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    857\u001b[0m   \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m    858\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# overridden).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m--> 863\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    865\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[0;32m    866\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[0;32m    867\u001b[0m                         build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:667\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 667\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    668\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    669\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    460\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\tmp3hmsdmz6.py:36\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m x_windows \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(window_partition), (ag__\u001b[39m.\u001b[39mld(shifted_x), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mwindow_size), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     35\u001b[0m x_windows \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mreshape, (ag__\u001b[39m.\u001b[39mld(x_windows),), \u001b[39mdict\u001b[39m(shape\u001b[39m=\u001b[39m((\u001b[39m-\u001b[39m \u001b[39m1\u001b[39m), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mwindow_size \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mwindow_size), ag__\u001b[39m.\u001b[39mld(C))), fscope)\n\u001b[1;32m---> 36\u001b[0m attn_windows \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mattn, (ag__\u001b[39m.\u001b[39;49mld(x_windows),), \u001b[39mdict\u001b[39;49m(mask\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mattn_mask), fscope)\n\u001b[0;32m     37\u001b[0m attn_windows \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mreshape, (ag__\u001b[39m.\u001b[39mld(attn_windows),), \u001b[39mdict\u001b[39m(shape\u001b[39m=\u001b[39m((\u001b[39m-\u001b[39m \u001b[39m1\u001b[39m), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mwindow_size, ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mwindow_size, ag__\u001b[39m.\u001b[39mld(C))), fscope)\n\u001b[0;32m     38\u001b[0m shifted_x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(window_reverse), (ag__\u001b[39m.\u001b[39mld(attn_windows), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mwindow_size, ag__\u001b[39m.\u001b[39mld(H), ag__\u001b[39m.\u001b[39mld(W), ag__\u001b[39m.\u001b[39mld(C)), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:396\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    393\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 396\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    398\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:478\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    475\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    479\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1012\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1008\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m   1010\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1014\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1015\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:667\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    666\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 667\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    668\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    669\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    460\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\tmpwx326xw0.py:48\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     46\u001b[0m mask_float \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mmask_float\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt((ag__\u001b[39m.\u001b[39mld(mask) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m), if_body, else_body, get_state, set_state, (\u001b[39m'\u001b[39m\u001b[39mattn\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m attn \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mattn_drop, (ag__\u001b[39m.\u001b[39;49mld(attn),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     49\u001b[0m x_qkv \u001b[39m=\u001b[39m (ag__\u001b[39m.\u001b[39mld(attn) \u001b[39m@\u001b[39m ag__\u001b[39m.\u001b[39mld(v))\n\u001b[0;32m     50\u001b[0m x_qkv \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mtranspose, (ag__\u001b[39m.\u001b[39mld(x_qkv),), \u001b[39mdict\u001b[39m(perm\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)), fscope)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:396\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    393\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 396\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    398\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:479\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 479\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1012\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1008\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m   1010\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1011\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1012\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1014\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1015\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:230\u001b[0m, in \u001b[0;36mDropout.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdropped_inputs\u001b[39m():\n\u001b[0;32m    224\u001b[0m   \u001b[39mreturn\u001b[39;00m nn\u001b[39m.\u001b[39mdropout(\n\u001b[0;32m    225\u001b[0m       inputs,\n\u001b[0;32m    226\u001b[0m       noise_shape\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_noise_shape(inputs),\n\u001b[0;32m    227\u001b[0m       seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed,\n\u001b[0;32m    228\u001b[0m       rate\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrate)\n\u001b[1;32m--> 230\u001b[0m output \u001b[39m=\u001b[39m control_flow_util\u001b[39m.\u001b[39;49msmart_cond(training, dropped_inputs,\n\u001b[0;32m    231\u001b[0m                                       \u001b[39mlambda\u001b[39;49;00m: array_ops\u001b[39m.\u001b[39;49midentity(inputs))\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\control_flow_util.py:114\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pred, variables\u001b[39m.\u001b[39mVariable):\n\u001b[0;32m    112\u001b[0m   \u001b[39mreturn\u001b[39;00m control_flow_ops\u001b[39m.\u001b[39mcond(\n\u001b[0;32m    113\u001b[0m       pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m smart_module\u001b[39m.\u001b[39;49msmart_cond(\n\u001b[0;32m    115\u001b[0m     pred, true_fn\u001b[39m=\u001b[39;49mtrue_fn, false_fn\u001b[39m=\u001b[39;49mfalse_fn, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:56\u001b[0m, in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m true_fn()\n\u001b[0;32m     55\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m false_fn()\n\u001b[0;32m     57\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   \u001b[39mreturn\u001b[39;00m control_flow_ops\u001b[39m.\u001b[39mcond(pred, true_fn\u001b[39m=\u001b[39mtrue_fn, false_fn\u001b[39m=\u001b[39mfalse_fn,\n\u001b[0;32m     59\u001b[0m                                name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:231\u001b[0m, in \u001b[0;36mDropout.call.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdropped_inputs\u001b[39m():\n\u001b[0;32m    224\u001b[0m   \u001b[39mreturn\u001b[39;00m nn\u001b[39m.\u001b[39mdropout(\n\u001b[0;32m    225\u001b[0m       inputs,\n\u001b[0;32m    226\u001b[0m       noise_shape\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_noise_shape(inputs),\n\u001b[0;32m    227\u001b[0m       seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed,\n\u001b[0;32m    228\u001b[0m       rate\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrate)\n\u001b[0;32m    230\u001b[0m output \u001b[39m=\u001b[39m control_flow_util\u001b[39m.\u001b[39msmart_cond(training, dropped_inputs,\n\u001b[1;32m--> 231\u001b[0m                                       \u001b[39mlambda\u001b[39;00m: array_ops\u001b[39m.\u001b[39;49midentity(inputs))\n\u001b[0;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    203\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    204\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:287\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgraph\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    284\u001b[0m   \u001b[39m# Make sure we get an input with handle data attached from resource\u001b[39;00m\n\u001b[0;32m    285\u001b[0m   \u001b[39m# variables. Variables have correct handle data when graph building.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m   \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39minput\u001b[39m)\n\u001b[1;32m--> 287\u001b[0m ret \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49midentity(\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    288\u001b[0m \u001b[39m# Propagate handle data for happier shape inference for resource variables.\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_handle_data\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3941\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   3939\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   3940\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> 3941\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   3942\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mIdentity\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   3943\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   3944\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:748\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    743\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    744\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    745\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    746\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    747\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 748\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    749\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    750\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    752\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    753\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:590\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    588\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    589\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 590\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    591\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    592\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3528\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3525\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3526\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3527\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3528\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3529\u001b[0m       node_def,\n\u001b[0;32m   3530\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3531\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3532\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3533\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3534\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3535\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3536\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3537\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3538\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2015\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2013\u001b[0m   \u001b[39mif\u001b[39;00m op_def \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2014\u001b[0m     op_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_get_op_def(node_def\u001b[39m.\u001b[39mop)\n\u001b[1;32m-> 2015\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op \u001b[39m=\u001b[39m _create_c_op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph, node_def, inputs,\n\u001b[0;32m   2016\u001b[0m                             control_input_ops, op_def)\n\u001b[0;32m   2017\u001b[0m   name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mname)\n\u001b[0;32m   2018\u001b[0m \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1853\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1849\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   1850\u001b[0m                                          serialized)\n\u001b[0;32m   1852\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1853\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   1854\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1855\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mstr\u001b[39m(e))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#define directory where images and masks are located on local disk\n",
    "image_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_images_RF/insert_images/'\n",
    "mask_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'\n",
    "#'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'\n",
    "\n",
    "#define the properties and empty list for resized images and masks\n",
    "SIZE = 256\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "\n",
    "#define custom functions\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n",
    "\n",
    "#enumerate and resize images/masks\n",
    "images = os.listdir(image_directory)\n",
    "for i, image_name in enumerate(images):    #enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        #print(image_directory+image_name)\n",
    "        image = cv2.imread(image_directory+image_name, 1)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        image_dataset.append(np.array(image))\n",
    "\n",
    "\n",
    "masks = os.listdir(mask_directory)\n",
    "for i, image_name in enumerate(masks):\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        image = cv2.imread(mask_directory+image_name, 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        mask_dataset.append(np.array(image))\n",
    "\n",
    "\n",
    "#define some hyperparameters\n",
    "num_labels = 2  #Binary classificaion (missmatch with literature/code examples!)\n",
    "batch_size = 2  #keep it smaller than 3\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "#normalize images\n",
    "image_dataset = np.array(image_dataset)/255\n",
    "#do not normalize masks, just rescale to 0 to 1. Add RGB-Chanel (3) to mask.\n",
    "mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255\n",
    "mask_dataset = tf.keras.utils.to_categorical(mask_dataset)\n",
    "\n",
    "\"\"\" plt.imshow(mask_dataset[1])\n",
    "plt.show()\n",
    "plt.imshow(image_dataset[1])\n",
    "plt.show() \"\"\"\n",
    "\n",
    "print(image_dataset[1].shape)\n",
    "print(mask_dataset[1].shape)\n",
    "\n",
    "#define callback function\n",
    "callbacks = [\n",
    "  EarlyStopping(patience=8, verbose=1),\n",
    "  ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "  ModelCheckpoint('A_modelSwinV1.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "  CSVLogger('A_modelSwinV1.csv', separator=',', append=False)]\n",
    "    \n",
    "#define the model architecture\n",
    "#this model requires depth >= 2\n",
    "model = models.swin_unet_2d((256, 256, 3), filter_num_begin=64, n_labels=num_labels, depth=4, stack_num_down=2, stack_num_up=2, \n",
    "                            patch_size=(4, 4), num_heads=[4, 8, 8, 8], window_size=[4, 2, 2, 2], num_mlp=512, \n",
    "                            output_activation='Softmax', shift_window=True, name='swin_unet') #Guess: Shift_window = False\n",
    "\n",
    "#compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "            metrics=['accuracy', IoU])\n",
    "\n",
    "#split dataset into training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.10, random_state = 0)\n",
    "\n",
    "#start time meauserment\n",
    "start2 = datetime.now() \n",
    "\n",
    "#fit model to data\n",
    "resunet_history = model.fit(X_train, y_train, \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(X_test, y_test), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "#stop time measurement and print the execution time\n",
    "stop2 = datetime.now() \n",
    "execution_time = stop2-start2\n",
    "print(\"R2-Unet fitting time is: \", execution_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define directory where images and masks are located on local disk\n",
    "image_directory = 'D:/UniBas/Bachelorarbeit/some_images/'\n",
    "mask_directory = 'D:/UniBas/Bachelorarbeit/some_masks/'\n",
    "#'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'\n",
    "\n",
    "#define the properties and empty list for resized images and masks\n",
    "SIZE = 256\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "\n",
    "#define custom functions\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n",
    "\n",
    "#enumerate and resize images/masks\n",
    "images = os.listdir(image_directory)\n",
    "for i, image_name in enumerate(images):    #enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        #print(image_directory+image_name)\n",
    "        image = cv2.imread(image_directory+image_name, 1)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        image_dataset.append(np.array(image))\n",
    "\n",
    "\n",
    "masks = os.listdir(mask_directory)\n",
    "for i, image_name in enumerate(masks):\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        image = cv2.imread(mask_directory+image_name, 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        mask_dataset.append(np.array(image))\n",
    "\n",
    "\n",
    "#define some hyperparameters\n",
    "num_labels = 2  #Binary classificaion (missmatch with literature/code examples!)\n",
    "batch_size = 2  #keep it smaller than 3\n",
    "epochs = 2\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#normalize images\n",
    "image_dataset = np.array(image_dataset)/255\n",
    "#do not normalize masks, just rescale to 0 to 1. Add RGB-Chanel (3) to mask.\n",
    "mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255\n",
    "mask_dataset = tf.keras.utils.to_categorical(mask_dataset)\n",
    "\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "#define callback function\n",
    "    callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(f'B_Kfold{fold_no}_SwinV1.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger(f'B_Kfold{fold_no}_SwinV1.csv', separator=',', append=False)]\n",
    "        \n",
    "    #define the model architecture\n",
    "    #this model requires depth >= 2\n",
    "    model = models.swin_unet_2d((256, 256, 3), filter_num_begin=64, n_labels=num_labels, depth=4, stack_num_down=2, stack_num_up=2, \n",
    "                                patch_size=(4, 4), num_heads=[4, 8, 8, 8], window_size=[4, 2, 2, 2], num_mlp=512, \n",
    "                                output_activation='Softmax', shift_window=True, name='swin_unet') #Guess: Shift_window = False\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "                metrics=['accuracy', IoU])\n",
    "\n",
    "    #split dataset into training and validation set\n",
    "\n",
    "    #start time meauserment\n",
    "    start2 = datetime.now() \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    #fit model to data\n",
    "    resunet_history = model.fit(image_dataset[train], mask_dataset[train], \n",
    "                        verbose=1,\n",
    "                        batch_size = batch_size,\n",
    "                        validation_data=(image_dataset[test], mask_dataset[test]), \n",
    "                        shuffle=False,\n",
    "                        epochs=epochs,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    fold_no += 1\n",
    "\n",
    "#stop time measurement and print the execution time\n",
    "stop2 = datetime.now() \n",
    "execution_time = stop2-start2\n",
    "print(\"Swin-Unet fitting time is: \", execution_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Swin with k-Fold (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/2\n",
      "205/205 [==============================] - 293s 1s/step - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_IoU: 1.0000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.62457, saving model to K-foldno1-swinunet-V1-VL-256.h5\n",
      "Epoch 2/2\n",
      "205/205 [==============================] - 255s 1s/step - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_IoU: 1.0000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 7.62457\n",
      "4/4 [==============================] - 11s 3s/step - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/2\n",
      "144/205 [====================>.........] - ETA: 1:19 - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000"
     ]
    }
   ],
   "source": [
    "#define directory where images and masks are located on local disk\n",
    "image_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_images_RF/insert_images/'\n",
    "mask_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'\n",
    "#'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'\n",
    "\n",
    "#define the properties and empty list for resized images and masks\n",
    "SIZE = 256\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "\n",
    "#define custom functions\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n",
    "\n",
    "#enumerate and resize images/masks\n",
    "images = os.listdir(image_directory)\n",
    "for i, image_name in enumerate(images):    #enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        #print(image_directory+image_name)\n",
    "        image = cv2.imread(image_directory+image_name, 1)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        image_dataset.append(np.array(image))\n",
    "\n",
    "\n",
    "masks = os.listdir(mask_directory)\n",
    "for i, image_name in enumerate(masks):\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        image = cv2.imread(mask_directory+image_name, 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        mask_dataset.append(np.array(image))\n",
    "\n",
    "#define some hyperparameters\n",
    "num_labels = 1  #Binary classificaion (missmatch on coding examples! 1 or 2 for binary classification)\n",
    "batch_size = 2  #keep it smaller than 3\n",
    "epochs = 2\n",
    "num_folds = 5   #define the number of folds (usually 5-10 folds)\n",
    "\n",
    "#normalize images\n",
    "image_dataset = np.array(image_dataset)/255\n",
    "#do not normalize masks, just rescale to 0 to 1. Add RGB-Chanel (3) to mask.\n",
    "mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255\n",
    "mask_dataset = tf.keras.utils.to_categorical(mask_dataset)\n",
    "\n",
    "#define K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "#define per-fold score containers \n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "IoU_per_fold = []\n",
    "\n",
    "#K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "  callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(f'K-foldno{fold_no}-swinunet-V1-VL-256.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger(f'K-foldno{fold_no}-swinunet-V1-VL-256.csv', separator=',', append=False)]\n",
    "  \n",
    "  #define the model architecture\n",
    "  #this model requires depth >= 2\n",
    "  model = models.swin_unet_2d((256, 256, 3), filter_num_begin=64, n_labels=num_labels, depth=4, stack_num_down=2, stack_num_up=2, \n",
    "                            patch_size=(4, 4), num_heads=[4, 8, 8, 8], window_size=[4, 2, 2, 2], num_mlp=512, \n",
    "                            output_activation='Softmax', shift_window=False, name='swin_unet') #Guess: Shift_window = False\n",
    "\n",
    "  #compile the model\n",
    "  model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "              metrics=['accuracy', IoU])\n",
    "\n",
    "  #generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  #fit model on data\n",
    "  swin_unet_history = model.fit(image_dataset[train], mask_dataset[train], \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(image_dataset[test], mask_dataset[test]), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "  #append evaluation values for every fold to a list\n",
    "  acc_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[1])\n",
    "  loss_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[0])\n",
    "  IoU_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[2])\n",
    "\n",
    "  #increase fold number\n",
    "  fold_no += 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - IoU: {IoU_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print(f'> IoU: {np.mean(IoU_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepACSA5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9838a3f48d92ef1e13f85ce4f6b5d67652e8280cf6406f0fff9e9d21f80d92c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
