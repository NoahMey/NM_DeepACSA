{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import random\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "#import glob\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use(\"ggplot\")\n",
    "#%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import cv2\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras_unet_collection import models #Keras unet collection\n",
    "from keras import utils\n",
    "#import tensorflow as tf\n",
    "from PIL import Image\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from skimage.io import imshow\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn import datasets\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.backend import clear_session\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.applications import VGG16 \n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Swin without k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, concatenate\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 256, 2)\n",
      "Epoch 1/2\n",
      " 28/230 [==>...........................] - ETA: 3:05 - loss: 0.5615 - accuracy: 0.8087 - IoU: 0.8471"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m start2 \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \n\u001b[0;32m     82\u001b[0m \u001b[39m#fit model to data\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m resunet_history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, \n\u001b[0;32m     84\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     85\u001b[0m                     batch_size \u001b[39m=\u001b[39;49m batch_size,\n\u001b[0;32m     86\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), \n\u001b[0;32m     87\u001b[0m                     shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     88\u001b[0m                     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     89\u001b[0m                     callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[0;32m     91\u001b[0m \u001b[39m#stop time measurement and print the execution time\u001b[39;00m\n\u001b[0;32m     92\u001b[0m stop2 \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow() \n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1094\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1095\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1096\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1097\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1098\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1099\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1100\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1101\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1102\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[1;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    852\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    853\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    854\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    857\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    858\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    859\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2940\u001b[0m   (graph_function,\n\u001b[0;32m   2941\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1914\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1916\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1917\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1919\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1920\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m     args,\n\u001b[0;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1923\u001b[0m     executing_eagerly)\n\u001b[0;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    556\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    557\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    558\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    559\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    560\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    561\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    563\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    564\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    567\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    568\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#define directory where images and masks are located on local disk\n",
    "image_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_images_RF/insert_images/'\n",
    "mask_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'\n",
    "#'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'\n",
    "\n",
    "#define the properties and empty list for resized images and masks\n",
    "SIZE = 256\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "\n",
    "#define custom functions\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n",
    "\n",
    "#enumerate and resize images/masks\n",
    "images = os.listdir(image_directory)\n",
    "for i, image_name in enumerate(images):    #enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        #print(image_directory+image_name)\n",
    "        image = cv2.imread(image_directory+image_name, 1)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        image_dataset.append(np.array(image))\n",
    "\n",
    "\n",
    "masks = os.listdir(mask_directory)\n",
    "for i, image_name in enumerate(masks):\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        image = cv2.imread(mask_directory+image_name, 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        mask_dataset.append(np.array(image))\n",
    "\n",
    "\n",
    "#define some hyperparameters\n",
    "num_labels = 2  #Binary classificaion (missmatch with literature/code examples!)\n",
    "batch_size = 2  #keep it smaller than 3\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "#normalize images\n",
    "image_dataset = np.array(image_dataset)/255\n",
    "#do not normalize masks, just rescale to 0 to 1. Add RGB-Chanel (3) to mask.\n",
    "mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255\n",
    "mask_dataset = tf.keras.utils.to_categorical(mask_dataset)\n",
    "\n",
    "\"\"\" plt.imshow(mask_dataset[1])\n",
    "plt.show()\n",
    "plt.imshow(image_dataset[1])\n",
    "plt.show() \"\"\"\n",
    "\n",
    "print(image_dataset[1].shape)\n",
    "print(mask_dataset[1].shape)\n",
    "\n",
    "#define callback function\n",
    "callbacks = [\n",
    "  EarlyStopping(patience=8, verbose=1),\n",
    "  ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "  ModelCheckpoint('A_modelSwinV1.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "  CSVLogger('A_modelSwinV1.csv', separator=',', append=False)]\n",
    "    \n",
    "#define the model architecture\n",
    "#this model requires depth >= 2\n",
    "model = models.swin_unet_2d((256, 256, 3), filter_num_begin=64, n_labels=num_labels, depth=4, stack_num_down=2, stack_num_up=2, \n",
    "                            patch_size=(4, 4), num_heads=[4, 8, 8, 8], window_size=[4, 2, 2, 2], num_mlp=512, \n",
    "                            output_activation='Softmax', shift_window=True, name='swin_unet') #Guess: Shift_window = False\n",
    "\n",
    "#compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "            metrics=['accuracy', IoU])\n",
    "\n",
    "#split dataset into training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset, mask_dataset, test_size = 0.10, random_state = 0)\n",
    "\n",
    "#start time meauserment\n",
    "start2 = datetime.now() \n",
    "\n",
    "#fit model to data\n",
    "resunet_history = model.fit(X_train, y_train, \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(X_test, y_test), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "#stop time measurement and print the execution time\n",
    "stop2 = datetime.now() \n",
    "execution_time = stop2-start2\n",
    "print(\"R2-Unet fitting time is: \", execution_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Swin with k-Fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/2\n",
      "205/205 [==============================] - 293s 1s/step - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_IoU: 1.0000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.62457, saving model to K-foldno1-swinunet-V1-VL-256.h5\n",
      "Epoch 2/2\n",
      "205/205 [==============================] - 255s 1s/step - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_IoU: 1.0000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 7.62457\n",
      "4/4 [==============================] - 11s 3s/step - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/2\n",
      " 77/205 [==========>...................] - ETA: 2:47 - loss: 7.6246 - accuracy: 0.5000 - IoU: 1.0000"
     ]
    }
   ],
   "source": [
    "#define directory where images and masks are located on local disk\n",
    "image_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_images_RF/insert_images/'\n",
    "mask_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'\n",
    "#'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'\n",
    "\n",
    "#define the properties and empty list for resized images and masks\n",
    "SIZE = 256\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "\n",
    "#define custom functions\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n",
    "\n",
    "#enumerate and resize images/masks\n",
    "images = os.listdir(image_directory)\n",
    "for i, image_name in enumerate(images):    #enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        #print(image_directory+image_name)\n",
    "        image = cv2.imread(image_directory+image_name, 1)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        image_dataset.append(np.array(image))\n",
    "\n",
    "\n",
    "masks = os.listdir(mask_directory)\n",
    "for i, image_name in enumerate(masks):\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        image = cv2.imread(mask_directory+image_name, 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        mask_dataset.append(np.array(image))\n",
    "\n",
    "#define some hyperparameters\n",
    "num_labels = 1  #Binary classificaion (missmatch on coding examples! 1 or 2 for binary classification)\n",
    "batch_size = 2  #keep it smaller than 3\n",
    "epochs = 2\n",
    "num_folds = 5   #define the number of folds (usually 5-10 folds)\n",
    "\n",
    "#normalize images\n",
    "image_dataset = np.array(image_dataset)/255\n",
    "#do not normalize masks, just rescale to 0 to 1. Add RGB-Chanel (3) to mask.\n",
    "mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255\n",
    "mask_dataset = tf.keras.utils.to_categorical(mask_dataset)\n",
    "\n",
    "#define K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "#define per-fold score containers \n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "IoU_per_fold = []\n",
    "\n",
    "#K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "  callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(f'K-foldno{fold_no}-swinunet-V1-VL-256.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger(f'K-foldno{fold_no}-swinunet-V1-VL-256.csv', separator=',', append=False)]\n",
    "  \n",
    "  #define the model architecture\n",
    "  #this model requires depth >= 2\n",
    "  model = models.swin_unet_2d((256, 256, 3), filter_num_begin=64, n_labels=num_labels, depth=4, stack_num_down=2, stack_num_up=2, \n",
    "                            patch_size=(4, 4), num_heads=[4, 8, 8, 8], window_size=[4, 2, 2, 2], num_mlp=512, \n",
    "                            output_activation='Softmax', shift_window=False, name='swin_unet') #Guess: Shift_window = False\n",
    "\n",
    "  #compile the model\n",
    "  model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "              metrics=['accuracy', IoU])\n",
    "\n",
    "  #generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  #fit model on data\n",
    "  swin_unet_history = model.fit(image_dataset[train], mask_dataset[train], \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(image_dataset[test], mask_dataset[test]), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "  #append evaluation values for every fold to a list\n",
    "  acc_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[1])\n",
    "  loss_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[0])\n",
    "  IoU_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[2])\n",
    "\n",
    "  #increase fold number\n",
    "  fold_no += 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - IoU: {IoU_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print(f'> IoU: {np.mean(IoU_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepACSA5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9838a3f48d92ef1e13f85ce4f6b5d67652e8280cf6406f0fff9e9d21f80d92c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
