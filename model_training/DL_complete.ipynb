{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import cv2\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#unet collection\n",
    "from keras_unet_collection import models\n",
    "#import tensorflow as tf\n",
    "from PIL import Image\n",
    "#Python 3.8.16 used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define directory where images and masks are located on local disk\n",
    "image_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/' ##VGG16 needs seperate induction of path\n",
    "mask_directory = 'D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'   ##VGG16 need seperate induction of path\n",
    "\n",
    "#define the properties and empty list for resized images and masks\n",
    "SIZE = 256\n",
    "image_dataset = []\n",
    "mask_dataset = []\n",
    "\n",
    "#define custom function\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n",
    "\n",
    "#enumerate and resize images/masks\n",
    "images = os.listdir(image_directory)\n",
    "for i, image_name in enumerate(images):    #enumerate method adds a counter and returns the enumerate object\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        #print(image_directory+image_name)\n",
    "        image = cv2.imread(image_directory+image_name, 1)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        image_dataset.append(np.array(image))\n",
    "\n",
    "masks = os.listdir(mask_directory)\n",
    "for i, image_name in enumerate(masks):\n",
    "    if (image_name.split('.')[1] == 'tif'):\n",
    "        image = cv2.imread(mask_directory+image_name, 0)\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((SIZE, SIZE))\n",
    "        mask_dataset.append(np.array(image))\n",
    "\n",
    "#define some hyperparameters\n",
    "num_labels = 1  #Binary classificaion\n",
    "batch_size = 2  #keep it smaller than 3\n",
    "epochs = 60\n",
    "num_folds = 5   #define the number of folds (usually 5-10 folds)\n",
    "\n",
    "#normalize images\n",
    "image_dataset = np.array(image_dataset)/255\n",
    "#do not normalize masks, just rescale to 0 to 1. Add RGB-Chanel (3) to mask.\n",
    "mask_dataset = np.expand_dims((np.array(mask_dataset)),3) /255\n",
    "\n",
    "#define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, random_state= 42 ,shuffle=True)\n",
    "\n",
    "#define per-fold score containers \n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "IoU_per_fold = []\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "#determine best fold and create csv file\n",
    "def best_fold(searchterm):\n",
    "    fo_path = os.getcwd() \n",
    "    max_val_iou = 0.0\n",
    "    fold = \"\"\n",
    "    for file_name in os.listdir(fo_path):\n",
    "        if searchterm in file_name and file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(fo_path, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(file_path)\n",
    "            if \"val_IoU\" in df.columns:\n",
    "                val_iou = df[\"val_IoU\"].max()\n",
    "            if val_iou > max_val_iou:\n",
    "                max_val_iou = val_iou\n",
    "                fold = file_name\n",
    "\n",
    "    #save the results to a CSV file\n",
    "    results = pd.DataFrame({\"fold\": [fold], \"max_val_iou\": [max_val_iou]})\n",
    "    results.to_csv(f\"{searchterm}results.csv\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL-Kfold with unet_2plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/60\n",
      " 14/205 [=>............................] - ETA: 5:17 - loss: 2.2922 - accuracy: 0.8546 - IoU: 0.7213"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining for fold \u001b[39m\u001b[39m{\u001b[39;00mfold_no\u001b[39m}\u001b[39;00m\u001b[39m ...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[39m#fit model to data\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m Unet_plus_history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(image_dataset[train], mask_dataset[train], \n\u001b[0;32m     31\u001b[0m                   verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     32\u001b[0m                   batch_size \u001b[39m=\u001b[39;49m batch_size,\n\u001b[0;32m     33\u001b[0m                   validation_data\u001b[39m=\u001b[39;49m(image_dataset[test], mask_dataset[test]), \n\u001b[0;32m     34\u001b[0m                   shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     35\u001b[0m                   epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     36\u001b[0m                   callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[0;32m     38\u001b[0m \u001b[39m#append evaluation values for every fold to a list\u001b[39;00m\n\u001b[0;32m     39\u001b[0m acc_per_fold\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mevaluate(image_dataset[test], mask_dataset[test])[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1094\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1095\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1096\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1097\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1098\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1099\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1100\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1101\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1102\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[1;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    852\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    853\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    854\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    857\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    858\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    859\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2940\u001b[0m   (graph_function,\n\u001b[0;32m   2941\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1914\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1916\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1917\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1919\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1920\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m     args,\n\u001b[0;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1923\u001b[0m     executing_eagerly)\n\u001b[0;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    556\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    557\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    558\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    559\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    560\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    561\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    563\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    564\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    567\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    568\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "architecture = \"unet_2plus\"\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "\n",
    "  callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(f\"B1VL-Kfoldno{fold_no}-{architecture}.h5\", verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger(f\"B1VL-Kfoldno{fold_no}-{architecture}.csv\", separator=\",\", append=False)]\n",
    "\n",
    "  #define the model architecture\n",
    "  #unet_plus_2d requires a Backbone\n",
    "  model = models.unet_plus_2d((256, 256, 3), filter_num=[64, 128, 256, 512, 1024], \n",
    "                           n_labels=num_labels, \n",
    "                           stack_num_down=2, stack_num_up=2, \n",
    "                           activation=\"ReLU\", \n",
    "                           output_activation=\"Sigmoid\", \n",
    "                           batch_norm=False, pool=False, unpool=False, \n",
    "                           backbone=\"VGG16\", weights=\"imagenet\", \n",
    "                           freeze_backbone=True, freeze_batch_norm=True, \n",
    "                           name=\"unet_plus\")\n",
    "\n",
    "  #compile the model\n",
    "  model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr = 1e-3), \n",
    "              metrics=[\"accuracy\", IoU])\n",
    "\n",
    "  #generate a print\n",
    "  print(\"------------------------------------------------------------------------\")\n",
    "  print(f\"Training for fold {fold_no} ...\")\n",
    "\n",
    "  #fit model to data\n",
    "  Unet_plus_history = model.fit(image_dataset[train], mask_dataset[train], \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(image_dataset[test], mask_dataset[test]), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "  \n",
    "  #append evaluation values for every fold to a list\n",
    "  acc_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[1])\n",
    "  loss_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[0])\n",
    "  IoU_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[2])\n",
    "\n",
    "  #increase fold number\n",
    "  fold_no += 1\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "#determine best fold\n",
    "best_fold(architecture)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL-Kfold with unet_3plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated hyper-parameter determination is applied with the following details:\n",
      "----------\n",
      "\tNumber of convolution filters after each full-scale skip connection: filter_num_skip = [64, 64, 64, 64]\n",
      "\tNumber of channels of full-scale aggregated feature maps: filter_num_aggregate = 320\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/60\n",
      "  1/205 [..............................] - ETA: 43:29 - loss: 0.6130 - accuracy: 0.8022 - IoU: 0.7103"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining for fold \u001b[39m\u001b[39m{\u001b[39;00mfold_no\u001b[39m}\u001b[39;00m\u001b[39m ...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[39m# Fit data to model\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m Unet_plus_history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(image_dataset[train], mask_dataset[train], \n\u001b[0;32m     25\u001b[0m                   verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     26\u001b[0m                   batch_size \u001b[39m=\u001b[39;49m batch_size,\n\u001b[0;32m     27\u001b[0m                   validation_data\u001b[39m=\u001b[39;49m(image_dataset[test], mask_dataset[test]), \n\u001b[0;32m     28\u001b[0m                   shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     29\u001b[0m                   epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     30\u001b[0m                   callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[0;32m     32\u001b[0m \u001b[39m#append evaluation values for every fold to a list\u001b[39;00m\n\u001b[0;32m     33\u001b[0m acc_per_fold\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mevaluate(image_dataset[test], mask_dataset[test])[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1094\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1095\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1096\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1097\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1098\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1099\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1100\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1101\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1102\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[1;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    852\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    853\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    854\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    857\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    858\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    859\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2940\u001b[0m   (graph_function,\n\u001b[0;32m   2941\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1914\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1916\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1917\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1919\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1920\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m     args,\n\u001b[0;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1923\u001b[0m     executing_eagerly)\n\u001b[0;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    556\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    557\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    558\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    559\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    560\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    561\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    563\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    564\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    567\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    568\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "architecture = \"unet_3plus\"\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "\n",
    "  callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(f'B1VL-Kfoldno{fold_no}-{architecture}.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger(f'B1VL-Kfoldno{fold_no}-{architecture}.csv', separator=',', append=False)]\n",
    "\n",
    "  # Define the model architecture\n",
    "  # unet_plus_2d require depth >= 2\n",
    "  model = models.unet_3plus_2d((256, 256, 3), n_labels=num_labels, filter_num_down=[64, 128, 256, 512, 1024], \n",
    "                             filter_num_skip='auto', filter_num_aggregate='auto', \n",
    "                             stack_num_down=2, stack_num_up=2, activation='ReLU', output_activation='Sigmoid',\n",
    "                             batch_norm=True, pool=True, unpool=False, deep_supervision=False, name='unet3plus')\n",
    "  # Compile the model\n",
    "  model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "              metrics=['accuracy', IoU])\n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  Unet_plus_history = model.fit(image_dataset[train], mask_dataset[train], \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(image_dataset[test], mask_dataset[test]), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "  \n",
    "  #append evaluation values for every fold to a list\n",
    "  acc_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[1])\n",
    "  loss_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[0])\n",
    "  IoU_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[2])\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no += 1\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "#determine best fold\n",
    "best_fold(architecture)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL-Kfold with Trans_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/60\n",
      "  3/205 [..............................] - ETA: 36:15 - loss: 0.5076 - accuracy: 0.9396 - IoU: 0.7646 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining for fold \u001b[39m\u001b[39m{\u001b[39;00mfold_no\u001b[39m}\u001b[39;00m\u001b[39m ...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[39m#fit model to data\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m transunet_history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(image_dataset[train], mask_dataset[train], \n\u001b[0;32m     26\u001b[0m                   verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     27\u001b[0m                   batch_size \u001b[39m=\u001b[39;49m batch_size,\n\u001b[0;32m     28\u001b[0m                   validation_data\u001b[39m=\u001b[39;49m(image_dataset[test], mask_dataset[test]), \n\u001b[0;32m     29\u001b[0m                   shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     30\u001b[0m                   epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     31\u001b[0m                   callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[0;32m     33\u001b[0m \u001b[39m#append evaluation values for every fold to a list\u001b[39;00m\n\u001b[0;32m     34\u001b[0m acc_per_fold\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mevaluate(image_dataset[test], mask_dataset[test])[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1094\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1095\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1096\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1097\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1098\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1099\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1100\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1101\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1102\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[1;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    852\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    853\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    854\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    857\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    858\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    859\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2940\u001b[0m   (graph_function,\n\u001b[0;32m   2941\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1914\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1916\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1917\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1919\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1920\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m     args,\n\u001b[0;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1923\u001b[0m     executing_eagerly)\n\u001b[0;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    556\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    557\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    558\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    559\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    560\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    561\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    563\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    564\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    567\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    568\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "architecture = \"Trans_unet\"\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "  callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(f'B1VL-Kfoldno{fold_no}-{architecture}.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger(f'B1VL-Kfoldno{fold_no}-{architecture}.csv', separator=',', append=False)]\n",
    "  \n",
    "  #define the model architecture\n",
    "  model = models.transunet_2d((256, 256, 3), filter_num=[64, 128, 256, 512, 1024], \n",
    "                          n_labels=num_labels, stack_num_down=2, stack_num_up=2, \n",
    "                          embed_dim=768, num_mlp=3072, num_heads=12, num_transformer=12, \n",
    "                          activation='ReLU', mlp_activation='GELU', output_activation='Sigmoid', #output activation from Softmax to Sigmoid\n",
    "                          batch_norm=True, pool=True, unpool=False, name='transunet')\n",
    "                          #batchnorm to true, unpool to false\n",
    "\n",
    "  #compile the model\n",
    "  model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "              metrics=['accuracy', IoU])\n",
    "\n",
    "  #generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  #fit model to data\n",
    "  transunet_history = model.fit(image_dataset[train], mask_dataset[train], \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(image_dataset[test], mask_dataset[test]), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "  #append evaluation values for every fold to a list\n",
    "  acc_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[1])\n",
    "  loss_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[0])\n",
    "  IoU_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[2])\n",
    "\n",
    "  #increase fold number\n",
    "  fold_no += 1\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "#determine best fold\n",
    "best_fold(architecture)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL-Kfold with Swin_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/60\n",
      "  1/205 [..............................] - ETA: 1:10:14 - loss: 14.3007 - accuracy: 0.0596 - IoU: 0.5311"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining for fold \u001b[39m\u001b[39m{\u001b[39;00mfold_no\u001b[39m}\u001b[39;00m\u001b[39m ...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[39m#fit model on data\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m swin_unet_history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(image_dataset[train], mask_dataset[train], \n\u001b[0;32m     24\u001b[0m                   verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     25\u001b[0m                   batch_size \u001b[39m=\u001b[39;49m batch_size,\n\u001b[0;32m     26\u001b[0m                   validation_data\u001b[39m=\u001b[39;49m(image_dataset[test], mask_dataset[test]), \n\u001b[0;32m     27\u001b[0m                   shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     28\u001b[0m                   epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     29\u001b[0m                   callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[0;32m     31\u001b[0m \u001b[39m#append evaluation values for every fold to a list\u001b[39;00m\n\u001b[0;32m     32\u001b[0m acc_per_fold\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mevaluate(image_dataset[test], mask_dataset[test])[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1094\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1095\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1096\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1097\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1098\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1099\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1100\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1101\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1102\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    827\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name) \u001b[39mas\u001b[39;00m tm:\n\u001b[1;32m--> 828\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    829\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m   new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    852\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    853\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    854\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 855\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    857\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    858\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    859\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2940\u001b[0m   (graph_function,\n\u001b[0;32m   2941\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1914\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1915\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1916\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1917\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1919\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1920\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m     args,\n\u001b[0;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1923\u001b[0m     executing_eagerly)\n\u001b[0;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    554\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    556\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    557\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    558\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    559\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    560\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    561\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    562\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    563\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    564\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    567\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    568\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Noah\\.conda\\envs\\DeepACSA5\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "architecture = \"Swin_unet\"\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "  callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(f'B1VL-Kfoldno{fold_no}-{architecture}.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger(f'B1VL-Kfoldno{fold_no}-{architecture}.csv', separator=',', append=False)]\n",
    "  \n",
    "  #define the model architecture\n",
    "  #this model requires depth >= 2\n",
    "  model = models.swin_unet_2d((256, 256, 3), filter_num_begin=64, n_labels=num_labels, depth=4, stack_num_down=2, stack_num_up=2, \n",
    "                            patch_size=(4, 4), num_heads=[4, 8, 8, 8], window_size=[4, 2, 2, 2], num_mlp=512, \n",
    "                            output_activation='Softmax', shift_window=False, name='swin_unet') #Guess: Shift_window = False\n",
    "\n",
    "  #compile the model\n",
    "  model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "              metrics=['accuracy', IoU])\n",
    "\n",
    "  #generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  #fit model on data\n",
    "  swin_unet_history = model.fit(image_dataset[train], mask_dataset[train], \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(image_dataset[test], mask_dataset[test]), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "  #append evaluation values for every fold to a list\n",
    "  acc_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[1])\n",
    "  loss_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[0])\n",
    "  IoU_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[2])\n",
    "\n",
    "  #increase fold number\n",
    "  fold_no += 1\n",
    "\n",
    "#determine best fold\n",
    "best_fold(architecture)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 with DL-Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of aponeurosis images =  512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 384\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39mD:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_images_RF/insert_images/\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    383\u001b[0m     \u001b[39mfor\u001b[39;00m img_path \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m\"\u001b[39m\u001b[39m*.tif\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m--> 384\u001b[0m         img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(img_path, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    385\u001b[0m         img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (\u001b[39m256\u001b[39m,\u001b[39m256\u001b[39m))\n\u001b[0;32m    386\u001b[0m         img \u001b[39m=\u001b[39m img_to_array(img)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from skimage.io import imshow\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn import datasets\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.backend import clear_session\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.applications import VGG16 \n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding = \"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, 3, padding = \"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs) #32\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_vgg16_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_tensor = inputs)\n",
    "    #vgg16.summary()\n",
    "    \n",
    "    \"\"\" Encoder \"\"\"\n",
    "    \n",
    "    # skip connections\n",
    "    s1 = vgg16.get_layer(\"block1_conv2\").output # 256\n",
    "    s2 = vgg16.get_layer(\"block2_conv2\").output # 128\n",
    "    s3 = vgg16.get_layer(\"block3_conv3\").output # 64\n",
    "    s4 = vgg16.get_layer(\"block4_conv3\").output # 32\n",
    "\n",
    "    \"\"\" Bottleneck/Bridge \"\"\"\n",
    "    \n",
    "    b1 = vgg16.get_layer(\"block5_conv3\").output # 16\n",
    "    \n",
    "    \"\"\" Decoder \"\"\"\n",
    "\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    \"\"\" Outputs \"\"\"\n",
    "    outputs = Conv2D(1, (1, 1), padding = \"same\", activation=\"sigmoid\")(d4) #binary segmentation\n",
    "    model = Model(inputs, outputs, name = \"VGG16_U-Net\")\n",
    "    return model\n",
    "    \n",
    "# Convolution block\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size), \\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Create u-net model\n",
    "def get_unet(input_img, n_filters = 64, dropout = 0.1, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    \n",
    "    # Contracting Path\n",
    "    # c is output tensor of conv layers\n",
    "    # p ist output tensor of max pool layers\n",
    "    # u is output tensor of up-sampling (transposed) layers\n",
    "    # Batchnorm standardizes/normalizes the output of each layer where applied in order to avoid huge weights using \n",
    "    # z-scores \n",
    "    \n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Compute Intersection over union (IoU), a measure of labelling accuracy\n",
    "# NOTE: This is sometimes also called Jaccard score\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n",
    "\n",
    "def dice_score(y_true, y_pred, smooth=1):\n",
    "    \n",
    "    # Flatten\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    \n",
    "    return 1 - dice_score(y_true, y_pred)\n",
    "\n",
    "def dice_bce_score(y_true, y_pred, smooth=1):    \n",
    "    \n",
    "    BCE =  K.binary_crossentropy(y_true, y_pred)\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)    \n",
    "    dice_loss = 1 - (2*intersection + smooth) / (K.sum(y_true, -1) + K.sum(y_pred, -1) + smooth)\n",
    "    Dice_BCE = BCE + dice_loss\n",
    "    \n",
    "    return Dice_BCE\n",
    "\n",
    "def focal_loss(y_true, y_pred, alpha=0.8, gamma=2):    \n",
    "      \n",
    "    BCE = K.binary_crossentropy(y_true, y_pred)\n",
    "    BCE_EXP = K.exp(-BCE)\n",
    "    focal_loss = K.mean(alpha * K.pow((1-BCE_EXP), gamma) * BCE)\n",
    "    return focal_loss\n",
    "\n",
    "# Plot sample of model prediction\n",
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(30, 20))\n",
    "    ax[0].imshow(X[ix, ..., 0], cmap='Greys_r')\n",
    "    \n",
    "    ax[0].set_title('US-image', c=\"white\" )\n",
    "    ax[0].grid(False)\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze(), cmap='Greys_r')\n",
    "    ax[1].set_title('Aponeurosis', c=\"white\")\n",
    "    ax[1].grid(False)\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1, cmap=\"Greys_r\")\n",
    "    \n",
    "    ax[2].set_title('Apo-Predicted', c=\"white\")\n",
    "    ax[2].grid(False)\n",
    "    \n",
    "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=0.5, cmap=\"Greys_r\")\n",
    "    \n",
    "    ax[3].set_title('Apo-Picture binary', c=\"white\")\n",
    "    ax[3].grid(False)\n",
    "    \n",
    "    plt.savefig(str(ix)+\"Pred_area.tif\")\n",
    "\n",
    "# Save all predictions on disk \n",
    "def save_pred_area(binary_preds): \n",
    "    for i in range(len(binary_preds)): \n",
    "        fig, (ax1)= plt.subplots(1, 1, figsize = (15, 15))\n",
    "        ax1.imshow(binary_preds[i], cmap=\"Greys_r\", interpolation=\"bilinear\")\n",
    "        ax1.set_title(\"Predicted Area\")\n",
    "        plt.savefig(str(i)+\"Pred_area.tif\") # Saves images to directory of notebook\n",
    "\n",
    "# Convolution block\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size), \\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Create u-net model\n",
    "def get_unet(input_img, n_filters = 64, dropout = 0.1, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    \n",
    "    # Contracting Path\n",
    "    # c is output tensor of conv layers\n",
    "    # p ist output tensor of max pool layers\n",
    "    # u is output tensor of up-sampling (transposed) layers\n",
    "    # Batchnorm standardizes/normalizes the output of each layer where applied in order to avoid huge weights using \n",
    "    # z-scores \n",
    "    \n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "# Compute Intersection over union (IoU), a measure of labelling accuracy\n",
    "# NOTE: This is sometimes also called Jaccard score\n",
    "def IoU(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "    iou = (intersection + smooth) / ( union + smooth)\n",
    "    return iou\n",
    "\n",
    "def dice_score(y_true, y_pred, smooth=1):\n",
    "    \n",
    "    # Flatten\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    \n",
    "    return 1 - dice_score(y_true, y_pred)\n",
    "\n",
    "def dice_bce_score(y_true, y_pred, smooth=1):    \n",
    "    \n",
    "    BCE =  K.binary_crossentropy(y_true, y_pred)\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)    \n",
    "    dice_loss = 1 - (2*intersection + smooth) / (K.sum(y_true, -1) + K.sum(y_pred, -1) + smooth)\n",
    "    Dice_BCE = BCE + dice_loss\n",
    "    \n",
    "    return Dice_BCE\n",
    "\n",
    "def focal_loss(y_true, y_pred, alpha=0.8, gamma=2):    \n",
    "      \n",
    "    BCE = K.binary_crossentropy(y_true, y_pred)\n",
    "    BCE_EXP = K.exp(-BCE)\n",
    "    focal_loss = K.mean(alpha * K.pow((1-BCE_EXP), gamma) * BCE)\n",
    "    return focal_loss\n",
    "\n",
    "# Plot sample of model prediction\n",
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(30, 20))\n",
    "    ax[0].imshow(X[ix, ..., 0], cmap='Greys_r')\n",
    "    \n",
    "    ax[0].set_title('US-image', c=\"white\" )\n",
    "    ax[0].grid(False)\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze(), cmap='Greys_r')\n",
    "    ax[1].set_title('Aponeurosis', c=\"white\")\n",
    "    ax[1].grid(False)\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1, cmap=\"Greys_r\")\n",
    "    \n",
    "    ax[2].set_title('Apo-Predicted', c=\"white\")\n",
    "    ax[2].grid(False)\n",
    "    \n",
    "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=0.5, cmap=\"Greys_r\")\n",
    "    \n",
    "    ax[3].set_title('Apo-Picture binary', c=\"white\")\n",
    "    ax[3].grid(False)\n",
    "    \n",
    "    plt.savefig(str(ix)+\"Pred_area.tif\")\n",
    "\n",
    "# Save all predictions on disk \n",
    "def save_pred_area(binary_preds): \n",
    "    for i in range(len(binary_preds)): \n",
    "        fig, (ax1)= plt.subplots(1, 1, figsize = (15, 15))\n",
    "        ax1.imshow(binary_preds[i], cmap=\"Greys_r\", interpolation=\"bilinear\")\n",
    "        ax1.set_title(\"Predicted Area\")\n",
    "        plt.savefig(str(i)+\"Pred_area.tif\") # Saves images to directory of notebook\n",
    "    \n",
    "# Images will be re-scaled\n",
    "im_width = 256\n",
    "im_height = 256\n",
    "border = 5\n",
    "\n",
    "# list of all images in the path\n",
    "ids = os.listdir('D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_images_RF/insert_images/')\n",
    "print(\"Total no. of aponeurosis images = \", len(ids))\n",
    "X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
    "y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
    "\n",
    "image_dataset = []\n",
    "for path in glob.glob('D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_images_RF/insert_images/'):\n",
    "    for img_path in glob.glob(os.path.join(path, \"*.tif\")):\n",
    "        img = cv2.imread(img_path, 1)\n",
    "        img = cv2.resize(img, (256,256))\n",
    "        img = img_to_array(img)\n",
    "        img = img/255.0\n",
    "        image_dataset.append(img)  \n",
    "image_dataset = np.array(image_dataset)\n",
    "\n",
    "mask_dataset = []\n",
    "for path in glob.glob('D:/UniBas/Bachelorarbeit/Img_masks/DeepACSA_masks_RF/insert_masks/'):\n",
    "    for mask_path in glob.glob(os.path.join(path, \"*.tif\")):\n",
    "        mask = cv2.imread(mask_path, 0)\n",
    "        mask = cv2.resize(mask, (256,256))\n",
    "        mask = img_to_array(mask)\n",
    "        mask = mask/255.0\n",
    "        mask_dataset.append(mask)\n",
    "        \n",
    "mask_dataset = np.array(mask_dataset)\n",
    "mask_dataset = np.expand_dims(mask_dataset, axis=3)\n",
    "###################################################################################\n",
    "batch_size = 2\n",
    "epochs = 60\n",
    "num_folds = 5\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "# Define per-fold score containers \n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "#compile the model\n",
    "VGG16_UNet = build_vgg16_unet((256,256,3)) #input_shape is (256, 256, 3)\n",
    "model_apo = VGG16_UNet\n",
    "model_apo.compile(optimizer=Adam(), loss=dice_bce_score, metrics=[\"accuracy\", IoU])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "architecture = \"VGG16\"\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "\n",
    "  callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(f'B1VL-Kfoldno{fold_no}-{architecture}.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger(f'B1VL-Kfoldno{fold_no}-{architecture}.csv', separator=',', append=False)\n",
    "  ]\n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  results = model_apo.fit(image_dataset[train], mask_dataset[train], batch_size=batch_size, epochs=epochs,\n",
    "                       callbacks=callbacks, validation_data=(image_dataset[test], mask_dataset[test]))\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "#determine best fold\n",
    "best_fold(architecture)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL-Kfold with ResUnet (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = \"ResUnet\"\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "  callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(f'B1VL-Kfoldno{fold_no}-{architecture}.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger(f'B1VL-Kfoldno{fold_no}-{architecture}.csv', separator=',', append=False)]\n",
    "\n",
    "  # Define the model architecture\n",
    "  # resunet requires depth >= 2\n",
    "  resunet = models.resunet_a_2d((256, 256, 3), [64, 128, 256, 512], \n",
    "                            dilation_num=[1, 3, 15, 31], \n",
    "                            n_labels=2, aspp_num_down=256, aspp_num_up=128, \n",
    "                            activation='ReLU', output_activation='Softmax', \n",
    "                            batch_norm=True, pool=\"max\", unpool='nearest', name='resunet')\n",
    "\n",
    "  # Compile the model\n",
    "  resunet.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "              metrics=['accuracy', IoU])\n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  resunet_history = resunet.fit(image_dataset[train], mask_dataset[train], \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(image_dataset[test], mask_dataset[test]), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "  #append evaluation values for every fold to a list\n",
    "  acc_per_fold.append(resunet.evaluate(image_dataset[test], mask_dataset[test])[1])\n",
    "  loss_per_fold.append(resunet.evaluate(image_dataset[test], mask_dataset[test])[0])\n",
    "  IoU_per_fold.append(resunet.evaluate(image_dataset[test], mask_dataset[test])[2])\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no += 1\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "#determine best fold\n",
    "best_fold(architecture)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL-Kfold with r2_unet (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = \"r2_unet\"\n",
    "for train, test in kfold.split(image_dataset, mask_dataset):\n",
    "  callbacks = [\n",
    "    EarlyStopping(patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint(f'B1VL-Kfoldno{fold_no}-{architecture}.h5', verbose=1, save_best_only=True, save_weights_only=False), # Give the model a name (the .h5 part)\n",
    "    CSVLogger(f'B1VL-Kfoldno{fold_no}-{architecture}.csv', separator=',', append=False)]                                  # Give the CSV file a name (.csv)\n",
    "\n",
    "  #define the model architecture\n",
    "  #r2_unet_2d requires depth >= 2\n",
    "  model = models.r2_unet_2d((256, 256, 3), [64, 128, 256, 512], n_labels=num_labels,\n",
    "                          stack_num_down=2, stack_num_up=2, recur_num=2,\n",
    "                          activation='ReLU', output_activation='Softmax', \n",
    "                          batch_norm=True, pool='max', unpool='nearest', name='r2unet')\n",
    "\n",
    "  #compile the model\n",
    "  model.compile(loss='binary_crossentropy', optimizer=Adam(lr = 1e-3), \n",
    "              metrics=['accuracy', IoU])\n",
    "\n",
    "  #generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  #fit model on data\n",
    "  resunet_history = model.fit(image_dataset[train], mask_dataset[train], \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(image_dataset[test], mask_dataset[test]), \n",
    "                    shuffle=False,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "  #append evaluation values for every fold to a list\n",
    "  acc_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[1])\n",
    "  loss_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[0])\n",
    "  IoU_per_fold.append(model.evaluate(image_dataset[test], mask_dataset[test])[2])\n",
    "\n",
    "  #increase fold number\n",
    "  fold_no += 1\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "#determine best fold\n",
    "best_fold(architecture)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide average scores for K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]} - IoU: {IoU_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print(f'> IoU: {np.mean(IoU_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepACSA5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
